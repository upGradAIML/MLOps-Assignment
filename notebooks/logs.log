2024-01-30 00:56:58,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:56:58,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:56:58,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:56:58,608:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:31,668:INFO:PyCaret ClassificationExperiment
2024-01-30 00:57:31,669:INFO:Logging name: Baseline_model_exp_01
2024-01-30 00:57:31,669:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-30 00:57:31,669:INFO:version 3.2.0
2024-01-30 00:57:31,669:INFO:Initializing setup()
2024-01-30 00:57:31,669:INFO:self.USI: f4eb
2024-01-30 00:57:31,669:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'log_plots_param', '_available_plots', 'exp_id', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'X_train', 'y_test', 'fold_generator', 'idx', 'exp_name_log', 'X', 'X_test', 'data', 'html_param', 'USI', 'logging_param', 'memory', 'y', 'is_multiclass', 'fold_groups_param', 'pipeline', 'gpu_param', 'y_train', 'seed'}
2024-01-30 00:57:31,669:INFO:Checking environment
2024-01-30 00:57:31,669:INFO:python_version: 3.10.12
2024-01-30 00:57:31,669:INFO:python_build: ('main', 'Jul  5 2023 18:54:27')
2024-01-30 00:57:31,669:INFO:machine: x86_64
2024-01-30 00:57:31,669:INFO:platform: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 00:57:31,669:INFO:Memory: svmem(total=67274690560, available=48850046976, percent=27.4, used=15118278656, free=767008768, active=26029744128, inactive=36697161728, buffers=865783808, cached=50523619328, shared=2563125248, slab=3078414336)
2024-01-30 00:57:31,670:INFO:Physical Core: 4
2024-01-30 00:57:31,671:INFO:Logical Core: 8
2024-01-30 00:57:31,672:INFO:Checking libraries
2024-01-30 00:57:31,672:INFO:System:
2024-01-30 00:57:31,673:INFO:    python: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]
2024-01-30 00:57:31,673:INFO:executable: /home/zinger/miniconda3/bin/python
2024-01-30 00:57:31,673:INFO:   machine: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 00:57:31,673:INFO:PyCaret required dependencies:
2024-01-30 00:57:32,235:INFO:                 pip: 23.0.1
2024-01-30 00:57:32,235:INFO:          setuptools: 66.1.1
2024-01-30 00:57:32,235:INFO:             pycaret: 3.2.0
2024-01-30 00:57:32,235:INFO:             IPython: 8.12.2
2024-01-30 00:57:32,235:INFO:          ipywidgets: 8.1.1
2024-01-30 00:57:32,235:INFO:                tqdm: 4.65.0
2024-01-30 00:57:32,235:INFO:               numpy: 1.25.2
2024-01-30 00:57:32,235:INFO:              pandas: 1.5.3
2024-01-30 00:57:32,235:INFO:              jinja2: 3.1.2
2024-01-30 00:57:32,235:INFO:               scipy: 1.10.1
2024-01-30 00:57:32,236:INFO:              joblib: 1.3.1
2024-01-30 00:57:32,236:INFO:             sklearn: 1.2.2
2024-01-30 00:57:32,236:INFO:                pyod: 1.1.2
2024-01-30 00:57:32,236:INFO:            imblearn: 0.11.0
2024-01-30 00:57:32,236:INFO:   category_encoders: 2.6.3
2024-01-30 00:57:32,236:INFO:            lightgbm: 4.1.0
2024-01-30 00:57:32,236:INFO:               numba: 0.58.1
2024-01-30 00:57:32,236:INFO:            requests: 2.31.0
2024-01-30 00:57:32,236:INFO:          matplotlib: 3.6.0
2024-01-30 00:57:32,236:INFO:          scikitplot: 0.3.7
2024-01-30 00:57:32,236:INFO:         yellowbrick: 1.5
2024-01-30 00:57:32,236:INFO:              plotly: 5.9.0
2024-01-30 00:57:32,236:INFO:    plotly-resampler: Not installed
2024-01-30 00:57:32,236:INFO:             kaleido: 0.2.1
2024-01-30 00:57:32,236:INFO:           schemdraw: 0.15
2024-01-30 00:57:32,236:INFO:         statsmodels: 0.14.0
2024-01-30 00:57:32,236:INFO:              sktime: 0.21.1
2024-01-30 00:57:32,236:INFO:               tbats: 1.1.3
2024-01-30 00:57:32,236:INFO:            pmdarima: 2.0.4
2024-01-30 00:57:32,236:INFO:              psutil: 5.9.6
2024-01-30 00:57:32,236:INFO:          markupsafe: 2.1.1
2024-01-30 00:57:32,236:INFO:             pickle5: Not installed
2024-01-30 00:57:32,236:INFO:         cloudpickle: 2.2.1
2024-01-30 00:57:32,237:INFO:         deprecation: 2.1.0
2024-01-30 00:57:32,237:INFO:              xxhash: 3.4.1
2024-01-30 00:57:32,237:INFO:           wurlitzer: 3.0.3
2024-01-30 00:57:32,237:INFO:PyCaret optional dependencies:
2024-01-30 00:57:32,404:INFO:                shap: 0.44.0
2024-01-30 00:57:32,404:INFO:           interpret: Not installed
2024-01-30 00:57:32,404:INFO:                umap: Not installed
2024-01-30 00:57:32,404:INFO:     ydata_profiling: 4.6.2
2024-01-30 00:57:32,404:INFO:  explainerdashboard: Not installed
2024-01-30 00:57:32,405:INFO:             autoviz: Not installed
2024-01-30 00:57:32,405:INFO:           fairlearn: Not installed
2024-01-30 00:57:32,405:INFO:          deepchecks: Not installed
2024-01-30 00:57:32,405:INFO:             xgboost: Not installed
2024-01-30 00:57:32,405:INFO:            catboost: Not installed
2024-01-30 00:57:32,405:INFO:              kmodes: Not installed
2024-01-30 00:57:32,405:INFO:             mlxtend: Not installed
2024-01-30 00:57:32,405:INFO:       statsforecast: Not installed
2024-01-30 00:57:32,405:INFO:        tune_sklearn: Not installed
2024-01-30 00:57:32,405:INFO:                 ray: Not installed
2024-01-30 00:57:32,405:INFO:            hyperopt: Not installed
2024-01-30 00:57:32,405:INFO:              optuna: Not installed
2024-01-30 00:57:32,405:INFO:               skopt: 0.9.0
2024-01-30 00:57:32,405:INFO:              mlflow: 2.8.1
2024-01-30 00:57:32,405:INFO:              gradio: Not installed
2024-01-30 00:57:32,405:INFO:             fastapi: Not installed
2024-01-30 00:57:32,405:INFO:             uvicorn: Not installed
2024-01-30 00:57:32,405:INFO:              m2cgen: Not installed
2024-01-30 00:57:32,405:INFO:           evidently: Not installed
2024-01-30 00:57:32,405:INFO:               fugue: Not installed
2024-01-30 00:57:32,405:INFO:           streamlit: 1.28.2
2024-01-30 00:57:32,405:INFO:             prophet: Not installed
2024-01-30 00:57:32,406:INFO:None
2024-01-30 00:57:32,406:INFO:Set up GPU usage.
2024-01-30 00:57:32,406:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:32,406:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-01-30 00:57:32,406:INFO:Set up data.
2024-01-30 00:57:32,564:INFO:Set up folding strategy.
2024-01-30 00:57:32,564:INFO:Set up train/test split.
2024-01-30 00:57:32,724:INFO:Set up index.
2024-01-30 00:57:32,730:INFO:Assigning column types.
2024-01-30 00:57:32,764:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-30 00:57:32,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:32,842:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 00:57:32,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:32,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:32,845:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 00:57:32,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:32,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:32,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:32,897:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:33,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:33,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:33,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 00:57:33,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:33,722:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:33,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 00:57:33,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:33,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:33,789:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:33,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:34,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:34,129:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-30 00:57:34,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,229:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 00:57:34,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:34,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:34,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 00:57:34,950:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:34,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:35,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:35,691:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-30 00:57:35,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:35,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:35,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:35,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:35,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:35,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:35,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:36,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:36,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:36,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:36,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:36,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:36,358:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:36,366:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:36,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:36,882:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:36,886:INFO:Preparing preprocessing pipeline...
2024-01-30 00:57:36,892:INFO:Set up simple imputation.
2024-01-30 00:57:36,944:INFO:Set up encoding of categorical features.
2024-01-30 00:57:37,375:INFO:Finished creating preprocessing pipeline.
2024-01-30 00:57:37,386:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 00:57:37,386:INFO:Creating final display dataframe.
2024-01-30 00:57:38,502:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape           (238964, 12)
4        Transformed data shape           (238964, 44)
5   Transformed train set shape           (167274, 44)
6    Transformed test set shape            (71690, 44)
7              Numeric features                      8
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment           MlflowLogger
20              Experiment Name  Baseline_model_exp_01
21                          USI                   f4eb
2024-01-30 00:57:38,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,643:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:38,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:38,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,952:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,960:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 00:57:38,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:39,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 00:57:39,362:INFO:Logging experiment in loggers
2024-01-30 00:57:40,093:INFO:SubProcess save_model() called ==================================
2024-01-30 00:57:40,112:INFO:Initializing save_model()
2024-01-30 00:57:40,112:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpyjlqmk6n/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-01-30 00:57:40,112:INFO:Adding model into prep_pipe
2024-01-30 00:57:40,112:WARNING:Only Model saved as it was a pipeline.
2024-01-30 00:57:40,121:INFO:/tmp/tmpyjlqmk6n/Transformation Pipeline.pkl saved in current working directory
2024-01-30 00:57:40,131:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 00:57:40,131:INFO:save_model() successfully completed......................................
2024-01-30 00:57:40,272:INFO:SubProcess save_model() end ==================================
2024-01-30 00:57:42,274:INFO:setup() successfully completed in 7.7s...............
2024-01-30 00:58:17,120:INFO:Initializing compare_models()
2024-01-30 00:58:17,120:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-01-30 00:58:17,120:INFO:Checking exceptions
2024-01-30 00:58:17,198:INFO:Preparing display monitor
2024-01-30 00:58:17,317:INFO:Initializing Logistic Regression
2024-01-30 00:58:17,317:INFO:Total runtime is 5.118052164713541e-06 minutes
2024-01-30 00:58:17,330:INFO:SubProcess create_model() called ==================================
2024-01-30 00:58:17,332:INFO:Initializing create_model()
2024-01-30 00:58:17,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 00:58:17,333:INFO:Checking exceptions
2024-01-30 00:58:17,333:INFO:Importing libraries
2024-01-30 00:58:17,334:INFO:Copying training dataset
2024-01-30 00:58:17,500:INFO:Defining folds
2024-01-30 00:58:17,500:INFO:Declaring metric variables
2024-01-30 00:58:17,508:INFO:Importing untrained model
2024-01-30 00:58:17,519:INFO:Logistic Regression Imported successfully
2024-01-30 00:58:17,540:INFO:Starting cross validation
2024-01-30 00:58:17,543:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 00:59:18,310:INFO:Calculating mean and std
2024-01-30 00:59:18,311:INFO:Creating metrics dataframe
2024-01-30 00:59:18,321:INFO:Uploading results into container
2024-01-30 00:59:18,323:INFO:Uploading model into container now
2024-01-30 00:59:18,324:INFO:_master_model_container: 1
2024-01-30 00:59:18,325:INFO:_display_container: 2
2024-01-30 00:59:18,326:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-30 00:59:18,326:INFO:create_model() successfully completed......................................
2024-01-30 00:59:18,505:INFO:SubProcess create_model() end ==================================
2024-01-30 00:59:18,506:INFO:Creating metrics dataframe
2024-01-30 00:59:18,524:INFO:Initializing Naive Bayes
2024-01-30 00:59:18,524:INFO:Total runtime is 1.0201249519983928 minutes
2024-01-30 00:59:18,531:INFO:SubProcess create_model() called ==================================
2024-01-30 00:59:18,532:INFO:Initializing create_model()
2024-01-30 00:59:18,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 00:59:18,532:INFO:Checking exceptions
2024-01-30 00:59:18,532:INFO:Importing libraries
2024-01-30 00:59:18,532:INFO:Copying training dataset
2024-01-30 00:59:18,718:INFO:Defining folds
2024-01-30 00:59:18,720:INFO:Declaring metric variables
2024-01-30 00:59:18,730:INFO:Importing untrained model
2024-01-30 00:59:18,737:INFO:Naive Bayes Imported successfully
2024-01-30 00:59:18,751:INFO:Starting cross validation
2024-01-30 00:59:18,754:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 00:59:26,938:INFO:Calculating mean and std
2024-01-30 00:59:26,940:INFO:Creating metrics dataframe
2024-01-30 00:59:26,952:INFO:Uploading results into container
2024-01-30 00:59:26,953:INFO:Uploading model into container now
2024-01-30 00:59:26,953:INFO:_master_model_container: 2
2024-01-30 00:59:26,954:INFO:_display_container: 2
2024-01-30 00:59:26,954:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-30 00:59:26,954:INFO:create_model() successfully completed......................................
2024-01-30 00:59:27,138:INFO:SubProcess create_model() end ==================================
2024-01-30 00:59:27,138:INFO:Creating metrics dataframe
2024-01-30 00:59:27,160:INFO:Initializing Decision Tree Classifier
2024-01-30 00:59:27,160:INFO:Total runtime is 1.1640602469444277 minutes
2024-01-30 00:59:27,167:INFO:SubProcess create_model() called ==================================
2024-01-30 00:59:27,168:INFO:Initializing create_model()
2024-01-30 00:59:27,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 00:59:27,168:INFO:Checking exceptions
2024-01-30 00:59:27,168:INFO:Importing libraries
2024-01-30 00:59:27,168:INFO:Copying training dataset
2024-01-30 00:59:27,306:INFO:Defining folds
2024-01-30 00:59:27,306:INFO:Declaring metric variables
2024-01-30 00:59:27,313:INFO:Importing untrained model
2024-01-30 00:59:27,319:INFO:Decision Tree Classifier Imported successfully
2024-01-30 00:59:27,332:INFO:Starting cross validation
2024-01-30 00:59:27,335:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 00:59:38,700:INFO:Calculating mean and std
2024-01-30 00:59:38,704:INFO:Creating metrics dataframe
2024-01-30 00:59:38,713:INFO:Uploading results into container
2024-01-30 00:59:38,714:INFO:Uploading model into container now
2024-01-30 00:59:38,715:INFO:_master_model_container: 3
2024-01-30 00:59:38,715:INFO:_display_container: 2
2024-01-30 00:59:38,716:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2024-01-30 00:59:38,717:INFO:create_model() successfully completed......................................
2024-01-30 00:59:38,898:INFO:SubProcess create_model() end ==================================
2024-01-30 00:59:38,898:INFO:Creating metrics dataframe
2024-01-30 00:59:38,917:INFO:Initializing Ridge Classifier
2024-01-30 00:59:38,917:INFO:Total runtime is 1.3600055138270062 minutes
2024-01-30 00:59:38,927:INFO:SubProcess create_model() called ==================================
2024-01-30 00:59:38,928:INFO:Initializing create_model()
2024-01-30 00:59:38,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 00:59:38,928:INFO:Checking exceptions
2024-01-30 00:59:38,928:INFO:Importing libraries
2024-01-30 00:59:38,928:INFO:Copying training dataset
2024-01-30 00:59:39,108:INFO:Defining folds
2024-01-30 00:59:39,108:INFO:Declaring metric variables
2024-01-30 00:59:39,115:INFO:Importing untrained model
2024-01-30 00:59:39,124:INFO:Ridge Classifier Imported successfully
2024-01-30 00:59:39,136:INFO:Starting cross validation
2024-01-30 00:59:39,138:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 00:59:47,693:INFO:Calculating mean and std
2024-01-30 00:59:47,702:INFO:Creating metrics dataframe
2024-01-30 00:59:47,711:INFO:Uploading results into container
2024-01-30 00:59:47,712:INFO:Uploading model into container now
2024-01-30 00:59:47,713:INFO:_master_model_container: 4
2024-01-30 00:59:47,713:INFO:_display_container: 2
2024-01-30 00:59:47,714:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-01-30 00:59:47,714:INFO:create_model() successfully completed......................................
2024-01-30 00:59:47,895:INFO:SubProcess create_model() end ==================================
2024-01-30 00:59:47,895:INFO:Creating metrics dataframe
2024-01-30 00:59:47,911:INFO:Initializing Random Forest Classifier
2024-01-30 00:59:47,912:INFO:Total runtime is 1.5099166075388593 minutes
2024-01-30 00:59:47,919:INFO:SubProcess create_model() called ==================================
2024-01-30 00:59:47,920:INFO:Initializing create_model()
2024-01-30 00:59:47,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 00:59:47,920:INFO:Checking exceptions
2024-01-30 00:59:47,920:INFO:Importing libraries
2024-01-30 00:59:47,920:INFO:Copying training dataset
2024-01-30 00:59:48,054:INFO:Defining folds
2024-01-30 00:59:48,054:INFO:Declaring metric variables
2024-01-30 00:59:48,062:INFO:Importing untrained model
2024-01-30 00:59:48,070:INFO:Random Forest Classifier Imported successfully
2024-01-30 00:59:48,087:INFO:Starting cross validation
2024-01-30 00:59:48,089:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 01:00:45,236:INFO:Calculating mean and std
2024-01-30 01:00:45,256:INFO:Creating metrics dataframe
2024-01-30 01:00:45,265:INFO:Uploading results into container
2024-01-30 01:00:45,268:INFO:Uploading model into container now
2024-01-30 01:00:45,269:INFO:_master_model_container: 5
2024-01-30 01:00:45,270:INFO:_display_container: 2
2024-01-30 01:00:45,270:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2024-01-30 01:00:45,270:INFO:create_model() successfully completed......................................
2024-01-30 01:00:45,496:INFO:SubProcess create_model() end ==================================
2024-01-30 01:00:45,497:INFO:Creating metrics dataframe
2024-01-30 01:00:45,525:INFO:Initializing Linear Discriminant Analysis
2024-01-30 01:00:45,526:INFO:Total runtime is 2.470151988665263 minutes
2024-01-30 01:00:45,539:INFO:SubProcess create_model() called ==================================
2024-01-30 01:00:45,539:INFO:Initializing create_model()
2024-01-30 01:00:45,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 01:00:45,539:INFO:Checking exceptions
2024-01-30 01:00:45,540:INFO:Importing libraries
2024-01-30 01:00:45,540:INFO:Copying training dataset
2024-01-30 01:00:45,751:INFO:Defining folds
2024-01-30 01:00:45,751:INFO:Declaring metric variables
2024-01-30 01:00:45,759:INFO:Importing untrained model
2024-01-30 01:00:45,772:INFO:Linear Discriminant Analysis Imported successfully
2024-01-30 01:00:45,791:INFO:Starting cross validation
2024-01-30 01:00:45,795:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 01:01:05,988:INFO:Calculating mean and std
2024-01-30 01:01:05,993:INFO:Creating metrics dataframe
2024-01-30 01:01:06,004:INFO:Uploading results into container
2024-01-30 01:01:06,006:INFO:Uploading model into container now
2024-01-30 01:01:06,006:INFO:_master_model_container: 6
2024-01-30 01:01:06,007:INFO:_display_container: 2
2024-01-30 01:01:06,011:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-30 01:01:06,012:INFO:create_model() successfully completed......................................
2024-01-30 01:01:06,271:INFO:SubProcess create_model() end ==================================
2024-01-30 01:01:06,272:INFO:Creating metrics dataframe
2024-01-30 01:01:06,301:INFO:Initializing Extra Trees Classifier
2024-01-30 01:01:06,301:INFO:Total runtime is 2.8164135217666626 minutes
2024-01-30 01:01:06,310:INFO:SubProcess create_model() called ==================================
2024-01-30 01:01:06,310:INFO:Initializing create_model()
2024-01-30 01:01:06,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 01:01:06,311:INFO:Checking exceptions
2024-01-30 01:01:06,311:INFO:Importing libraries
2024-01-30 01:01:06,311:INFO:Copying training dataset
2024-01-30 01:01:06,543:INFO:Defining folds
2024-01-30 01:01:06,543:INFO:Declaring metric variables
2024-01-30 01:01:06,553:INFO:Importing untrained model
2024-01-30 01:01:06,568:INFO:Extra Trees Classifier Imported successfully
2024-01-30 01:01:06,584:INFO:Starting cross validation
2024-01-30 01:01:06,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 01:02:23,214:INFO:Calculating mean and std
2024-01-30 01:02:23,222:INFO:Creating metrics dataframe
2024-01-30 01:02:23,232:INFO:Uploading results into container
2024-01-30 01:02:23,234:INFO:Uploading model into container now
2024-01-30 01:02:23,236:INFO:_master_model_container: 7
2024-01-30 01:02:23,236:INFO:_display_container: 2
2024-01-30 01:02:23,237:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2024-01-30 01:02:23,237:INFO:create_model() successfully completed......................................
2024-01-30 01:02:23,479:INFO:SubProcess create_model() end ==================================
2024-01-30 01:02:23,479:INFO:Creating metrics dataframe
2024-01-30 01:02:23,508:INFO:Initializing Light Gradient Boosting Machine
2024-01-30 01:02:23,508:INFO:Total runtime is 4.103193664550782 minutes
2024-01-30 01:02:23,520:INFO:SubProcess create_model() called ==================================
2024-01-30 01:02:23,521:INFO:Initializing create_model()
2024-01-30 01:02:23,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d30c6860>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 01:02:23,521:INFO:Checking exceptions
2024-01-30 01:02:23,521:INFO:Importing libraries
2024-01-30 01:02:23,522:INFO:Copying training dataset
2024-01-30 01:02:23,699:INFO:Defining folds
2024-01-30 01:02:23,700:INFO:Declaring metric variables
2024-01-30 01:02:23,709:INFO:Importing untrained model
2024-01-30 01:02:23,721:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 01:02:23,740:INFO:Starting cross validation
2024-01-30 01:02:23,744:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 01:02:26,271:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 01:02:26,296:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 01:02:26,707:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 01:02:26,739:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 01:02:26,888:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 01:02:26,888:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 01:02:26,926:WARNING:1 warning generated.
2024-01-30 01:02:26,953:WARNING:1 warning generated.
2024-01-30 01:02:26,981:WARNING:1 warning generated.
2024-01-30 01:02:27,012:WARNING:1 warning generated.
2024-01-30 01:02:27,691:WARNING:1 warning generated.
2024-01-30 01:02:27,721:WARNING:1 warning generated.
2024-01-30 01:02:28,193:WARNING:1 warning generated.
2024-01-30 01:02:28,404:WARNING:1 warning generated.
2024-01-30 01:02:28,852:WARNING:1 warning generated.
2024-01-30 01:02:29,094:WARNING:1 warning generated.
2024-01-30 01:02:29,320:WARNING:1 warning generated.
2024-01-30 01:02:29,623:WARNING:1 warning generated.
2024-01-30 01:02:29,669:WARNING:1 warning generated.
2024-01-30 01:02:29,933:WARNING:1 warning generated.
2024-01-30 01:02:29,958:WARNING:1 warning generated.
2024-01-30 01:02:30,171:WARNING:1 warning generated.
2024-01-30 01:02:30,436:WARNING:1 warning generated.
2024-01-30 01:02:30,625:WARNING:1 warning generated.
2024-01-30 01:02:31,122:WARNING:1 warning generated.
2024-01-30 01:02:31,152:WARNING:1 warning generated.
2024-01-30 01:02:31,587:WARNING:1 warning generated.
2024-01-30 01:02:32,025:WARNING:1 warning generated.
2024-01-30 01:02:32,223:WARNING:1 warning generated.
2024-01-30 01:02:32,247:WARNING:1 warning generated.
2024-01-30 01:02:32,725:WARNING:1 warning generated.
2024-01-30 01:02:32,977:WARNING:1 warning generated.
2024-01-30 01:02:33,226:WARNING:1 warning generated.
2024-01-30 01:02:33,464:WARNING:1 warning generated.
2024-01-30 01:02:33,489:WARNING:1 warning generated.
2024-01-30 01:02:34,009:WARNING:1 warning generated.
2024-01-30 01:02:34,033:WARNING:1 warning generated.
2024-01-30 01:02:34,060:WARNING:1 warning generated.
2024-01-30 01:02:34,615:WARNING:1 warning generated.
2024-01-30 01:02:34,903:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 01:02:34,905:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 01:02:35,047:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.141270 secs. 1 sparse feature groups
2024-01-30 01:02:35,099:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 01:02:35,149:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 01:10:11,107:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 01:10:11,127:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 01:10:11,407:INFO:[LightGBM] [Info] Total Bins 158
2024-01-30 01:10:11,449:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 01:10:11,558:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 01:10:11,558:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 01:10:11,647:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 01:10:11,650:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 01:10:11,851:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.195634 secs. 1 sparse feature groups
2024-01-30 01:10:11,919:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 01:10:11,940:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 01:12:37,756:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 01:12:37,774:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 01:12:38,074:INFO:[LightGBM] [Info] Total Bins 167
2024-01-30 01:12:38,091:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 01:12:38,199:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 01:12:38,199:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 01:12:38,273:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 01:12:38,276:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 01:12:38,459:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.182954 secs. 1 sparse feature groups
2024-01-30 01:12:38,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 01:12:38,578:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 01:16:36,461:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 01:16:36,470:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 01:16:36,705:INFO:[LightGBM] [Info] Total Bins 170
2024-01-30 01:16:36,712:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 01:16:36,822:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 01:16:36,825:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 01:16:36,887:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 01:16:36,889:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 01:16:37,000:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.110669 secs. 1 sparse feature groups
2024-01-30 01:16:37,023:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 01:16:37,049:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 01:16:58,967:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 01:16:58,995:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 01:16:59,341:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 01:16:59,383:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 41
2024-01-30 01:16:59,486:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 01:16:59,487:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 01:16:59,531:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 01:16:59,537:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 01:16:59,624:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.086410 secs. 1 sparse feature groups
2024-01-30 01:16:59,644:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 01:16:59,667:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 01:24:42,000:INFO:Calculating mean and std
2024-01-30 01:24:42,006:INFO:Creating metrics dataframe
2024-01-30 01:24:42,015:INFO:Uploading results into container
2024-01-30 01:24:42,016:INFO:Uploading model into container now
2024-01-30 01:24:42,017:INFO:_master_model_container: 8
2024-01-30 01:24:42,017:INFO:_display_container: 2
2024-01-30 01:24:42,018:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 01:24:42,018:INFO:create_model() successfully completed......................................
2024-01-30 01:24:42,306:INFO:SubProcess create_model() end ==================================
2024-01-30 01:24:42,306:INFO:Creating metrics dataframe
2024-01-30 01:24:42,374:INFO:Initializing create_model()
2024-01-30 01:24:42,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 01:24:42,379:INFO:Checking exceptions
2024-01-30 01:24:42,383:INFO:Importing libraries
2024-01-30 01:24:42,384:INFO:Copying training dataset
2024-01-30 01:24:42,549:INFO:Defining folds
2024-01-30 01:24:42,550:INFO:Declaring metric variables
2024-01-30 01:24:42,550:INFO:Importing untrained model
2024-01-30 01:24:42,550:INFO:Declaring custom model
2024-01-30 01:24:42,551:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 01:24:42,554:INFO:Cross validation set to False
2024-01-30 01:24:42,555:INFO:Fitting Model
2024-01-30 01:24:45,554:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 01:24:45,623:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 01:24:46,283:INFO:[LightGBM] [Info] Total Bins 175
2024-01-30 01:24:46,319:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 42
2024-01-30 01:24:46,457:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 01:24:46,458:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 01:24:46,533:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 01:24:46,551:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 01:24:46,647:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.095869 secs. 1 sparse feature groups
2024-01-30 01:24:46,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 01:24:46,719:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 01:30:51,364:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 01:30:51,364:INFO:create_model() successfully completed......................................
2024-01-30 01:30:51,598:INFO:Creating Dashboard logs
2024-01-30 01:30:51,608:INFO:Model: Light Gradient Boosting Machine
2024-01-30 01:30:51,690:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 01:30:52,311:INFO:Initializing predict_model()
2024-01-30 01:30:52,311:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f86cb3775b0>)
2024-01-30 01:30:52,311:INFO:Checking exceptions
2024-01-30 01:30:52,311:INFO:Preloading libraries
2024-01-30 01:30:53,870:INFO:SubProcess plot_model() called ==================================
2024-01-30 01:30:53,871:INFO:Initializing plot_model()
2024-01-30 01:30:53,871:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmph97kw_5y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, system=False)
2024-01-30 01:30:53,871:INFO:Checking exceptions
2024-01-30 01:30:53,926:INFO:Preloading libraries
2024-01-30 01:30:53,967:INFO:Copying training dataset
2024-01-30 01:30:53,967:INFO:Plot type: auc
2024-01-30 01:30:54,730:INFO:Fitting Model
2024-01-30 01:30:54,740:INFO:Scoring test/hold-out set
2024-01-30 01:30:55,315:INFO:Saving '/tmp/tmph97kw_5y/AUC.png'
2024-01-30 01:30:55,899:INFO:Visual Rendered Successfully
2024-01-30 01:30:56,057:INFO:plot_model() successfully completed......................................
2024-01-30 01:30:56,059:INFO:Initializing plot_model()
2024-01-30 01:30:56,059:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmph97kw_5y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, system=False)
2024-01-30 01:30:56,059:INFO:Checking exceptions
2024-01-30 01:30:56,094:INFO:Preloading libraries
2024-01-30 01:30:56,167:INFO:Copying training dataset
2024-01-30 01:30:56,167:INFO:Plot type: confusion_matrix
2024-01-30 01:30:56,860:INFO:Fitting Model
2024-01-30 01:30:56,864:INFO:Scoring test/hold-out set
2024-01-30 01:30:57,630:INFO:Saving '/tmp/tmph97kw_5y/Confusion Matrix.png'
2024-01-30 01:30:57,981:INFO:Visual Rendered Successfully
2024-01-30 01:30:58,248:INFO:plot_model() successfully completed......................................
2024-01-30 01:30:58,250:INFO:Initializing plot_model()
2024-01-30 01:30:58,251:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmph97kw_5y, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, system=False)
2024-01-30 01:30:58,251:INFO:Checking exceptions
2024-01-30 01:30:58,309:INFO:Preloading libraries
2024-01-30 01:30:58,357:INFO:Copying training dataset
2024-01-30 01:30:58,360:INFO:Plot type: feature
2024-01-30 01:30:58,379:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 01:30:58,648:INFO:Saving '/tmp/tmph97kw_5y/Feature Importance.png'
2024-01-30 01:30:59,018:INFO:Visual Rendered Successfully
2024-01-30 01:30:59,199:INFO:plot_model() successfully completed......................................
2024-01-30 01:30:59,201:INFO:SubProcess plot_model() end ==================================
2024-01-30 01:30:59,691:INFO:Creating Dashboard logs
2024-01-30 01:30:59,700:INFO:Model: Random Forest Classifier
2024-01-30 01:30:59,781:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 01:31:00,830:INFO:Creating Dashboard logs
2024-01-30 01:31:00,840:INFO:Model: Extra Trees Classifier
2024-01-30 01:31:00,926:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 01:31:02,096:INFO:Creating Dashboard logs
2024-01-30 01:31:02,102:INFO:Model: Decision Tree Classifier
2024-01-30 01:31:02,196:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2024-01-30 01:31:03,324:INFO:Creating Dashboard logs
2024-01-30 01:31:03,352:INFO:Model: Logistic Regression
2024-01-30 01:31:03,428:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-01-30 01:31:04,464:INFO:Creating Dashboard logs
2024-01-30 01:31:04,472:INFO:Model: Linear Discriminant Analysis
2024-01-30 01:31:04,569:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-01-30 01:31:05,664:INFO:Creating Dashboard logs
2024-01-30 01:31:05,673:INFO:Model: Ridge Classifier
2024-01-30 01:31:05,745:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2024-01-30 01:31:06,654:INFO:Creating Dashboard logs
2024-01-30 01:31:06,661:INFO:Model: Naive Bayes
2024-01-30 01:31:06,734:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-01-30 01:31:07,760:INFO:_master_model_container: 8
2024-01-30 01:31:07,762:INFO:_display_container: 2
2024-01-30 01:31:07,762:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 01:31:07,763:INFO:compare_models() successfully completed......................................
2024-01-30 02:06:07,881:INFO:Initializing create_model()
2024-01-30 02:06:07,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 02:06:07,882:INFO:Checking exceptions
2024-01-30 02:06:07,930:INFO:Importing libraries
2024-01-30 02:06:07,930:INFO:Copying training dataset
2024-01-30 02:06:08,090:INFO:Defining folds
2024-01-30 02:06:08,090:INFO:Declaring metric variables
2024-01-30 02:06:08,099:INFO:Importing untrained model
2024-01-30 02:06:08,108:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 02:06:08,150:INFO:Starting cross validation
2024-01-30 02:06:08,152:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 02:06:09,673:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 02:06:09,698:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 02:06:09,927:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 02:06:09,954:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 02:06:10,055:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 02:06:10,055:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 02:06:10,148:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 02:06:10,151:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 02:06:10,247:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.095307 secs. 1 sparse feature groups
2024-01-30 02:06:10,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 02:06:10,299:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 02:06:40,899:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 02:06:40,919:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 02:06:41,157:INFO:[LightGBM] [Info] Total Bins 158
2024-01-30 02:06:41,181:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 02:06:41,277:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 02:06:41,277:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 02:06:41,327:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 02:06:41,330:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 02:06:41,512:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.181886 secs. 1 sparse feature groups
2024-01-30 02:06:41,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 02:06:41,579:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 02:07:20,489:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 02:07:20,505:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 02:07:20,767:INFO:[LightGBM] [Info] Total Bins 167
2024-01-30 02:07:20,787:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 02:07:20,892:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 02:07:20,892:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 02:07:20,987:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 02:07:20,989:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 02:07:21,171:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.182681 secs. 1 sparse feature groups
2024-01-30 02:07:21,203:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 02:07:21,243:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 02:08:04,567:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 02:08:04,611:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 02:08:05,160:INFO:[LightGBM] [Info] Total Bins 170
2024-01-30 02:08:05,184:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 02:08:05,299:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 02:08:05,307:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 02:08:05,385:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 02:08:05,395:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 02:08:05,477:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.081510 secs. 1 sparse feature groups
2024-01-30 02:08:05,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 02:08:05,506:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 02:08:38,893:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 02:08:38,909:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 02:08:39,140:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 02:08:39,155:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 41
2024-01-30 02:08:39,261:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 02:08:39,261:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 02:08:39,345:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 02:08:39,349:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 02:08:39,456:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.107067 secs. 1 sparse feature groups
2024-01-30 02:08:39,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 02:08:39,500:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 02:08:56,879:INFO:Calculating mean and std
2024-01-30 02:08:56,881:INFO:Creating metrics dataframe
2024-01-30 02:08:56,896:INFO:Finalizing model
2024-01-30 02:08:58,408:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 02:08:58,432:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 02:08:58,692:INFO:[LightGBM] [Info] Total Bins 175
2024-01-30 02:08:58,713:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 42
2024-01-30 02:08:58,794:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 02:08:58,794:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 02:08:58,874:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 02:08:58,876:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 02:08:58,982:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.106418 secs. 1 sparse feature groups
2024-01-30 02:08:59,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 02:08:59,060:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 02:09:25,483:INFO:Creating Dashboard logs
2024-01-30 02:09:25,492:INFO:Model: Light Gradient Boosting Machine
2024-01-30 02:09:25,561:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 02:09:26,057:INFO:Initializing predict_model()
2024-01-30 02:09:26,058:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f86d1495120>)
2024-01-30 02:09:26,058:INFO:Checking exceptions
2024-01-30 02:09:26,058:INFO:Preloading libraries
2024-01-30 02:09:27,379:INFO:SubProcess plot_model() called ==================================
2024-01-30 02:09:27,380:INFO:Initializing plot_model()
2024-01-30 02:09:27,380:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpe4odl5nk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, system=False)
2024-01-30 02:09:27,380:INFO:Checking exceptions
2024-01-30 02:09:27,430:INFO:Preloading libraries
2024-01-30 02:09:27,504:INFO:Copying training dataset
2024-01-30 02:09:27,504:INFO:Plot type: auc
2024-01-30 02:09:28,091:INFO:Fitting Model
2024-01-30 02:09:28,097:INFO:Scoring test/hold-out set
2024-01-30 02:09:28,582:INFO:Saving '/tmp/tmpe4odl5nk/AUC.png'
2024-01-30 02:09:29,035:INFO:Visual Rendered Successfully
2024-01-30 02:09:29,216:INFO:plot_model() successfully completed......................................
2024-01-30 02:09:29,219:INFO:Initializing plot_model()
2024-01-30 02:09:29,220:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpe4odl5nk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, system=False)
2024-01-30 02:09:29,220:INFO:Checking exceptions
2024-01-30 02:09:29,265:INFO:Preloading libraries
2024-01-30 02:09:29,380:INFO:Copying training dataset
2024-01-30 02:09:29,380:INFO:Plot type: confusion_matrix
2024-01-30 02:09:30,023:INFO:Fitting Model
2024-01-30 02:09:30,026:INFO:Scoring test/hold-out set
2024-01-30 02:09:30,517:INFO:Saving '/tmp/tmpe4odl5nk/Confusion Matrix.png'
2024-01-30 02:09:30,763:INFO:Visual Rendered Successfully
2024-01-30 02:09:30,895:INFO:plot_model() successfully completed......................................
2024-01-30 02:09:30,897:INFO:Initializing plot_model()
2024-01-30 02:09:30,897:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpe4odl5nk, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, system=False)
2024-01-30 02:09:30,898:INFO:Checking exceptions
2024-01-30 02:09:30,954:INFO:Preloading libraries
2024-01-30 02:09:30,990:INFO:Copying training dataset
2024-01-30 02:09:30,990:INFO:Plot type: feature
2024-01-30 02:09:31,006:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 02:09:31,247:INFO:Saving '/tmp/tmpe4odl5nk/Feature Importance.png'
2024-01-30 02:09:31,597:INFO:Visual Rendered Successfully
2024-01-30 02:09:31,766:INFO:plot_model() successfully completed......................................
2024-01-30 02:09:31,767:INFO:SubProcess plot_model() end ==================================
2024-01-30 02:09:32,101:INFO:Uploading results into container
2024-01-30 02:09:32,102:INFO:Uploading model into container now
2024-01-30 02:09:32,118:INFO:_master_model_container: 9
2024-01-30 02:09:32,118:INFO:_display_container: 3
2024-01-30 02:09:32,119:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 02:09:32,119:INFO:create_model() successfully completed......................................
2024-01-30 07:23:19,386:INFO:Initializing plot_model()
2024-01-30 07:23:19,387:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86cb668a00>, system=True)
2024-01-30 07:23:19,387:INFO:Checking exceptions
2024-01-30 07:23:19,486:INFO:Preloading libraries
2024-01-30 07:23:19,499:INFO:Copying training dataset
2024-01-30 07:23:19,499:INFO:Plot type: feature_all
2024-01-30 07:23:19,627:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 07:23:20,067:INFO:Visual Rendered Successfully
2024-01-30 07:23:20,329:INFO:plot_model() successfully completed......................................
2024-01-30 07:23:27,744:INFO:PyCaret ClassificationExperiment
2024-01-30 07:23:27,744:INFO:Logging name: Baseline_model_exp_02
2024-01-30 07:23:27,744:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-30 07:23:27,744:INFO:version 3.2.0
2024-01-30 07:23:27,744:INFO:Initializing setup()
2024-01-30 07:23:27,745:INFO:self.USI: 4dec
2024-01-30 07:23:27,745:INFO:self._variable_keys: {'target_param', 'gpu_n_jobs_param', 'log_plots_param', '_available_plots', 'exp_id', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'n_jobs_param', 'X_train', 'y_test', 'fold_generator', 'idx', 'exp_name_log', 'X', 'X_test', 'data', 'html_param', 'USI', 'logging_param', 'memory', 'y', 'is_multiclass', 'fold_groups_param', 'pipeline', 'gpu_param', 'y_train', 'seed'}
2024-01-30 07:23:27,745:INFO:Checking environment
2024-01-30 07:23:27,745:INFO:python_version: 3.10.12
2024-01-30 07:23:27,745:INFO:python_build: ('main', 'Jul  5 2023 18:54:27')
2024-01-30 07:23:27,745:INFO:machine: x86_64
2024-01-30 07:23:27,745:INFO:platform: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 07:23:27,745:INFO:Memory: svmem(total=67274690560, available=60160794624, percent=10.6, used=5406146560, free=51061059584, active=7476822016, inactive=5884968960, buffers=4120576, cached=10803363840, shared=867405824, slab=2220261376)
2024-01-30 07:23:27,749:INFO:Physical Core: 4
2024-01-30 07:23:27,749:INFO:Logical Core: 8
2024-01-30 07:23:27,749:INFO:Checking libraries
2024-01-30 07:23:27,749:INFO:System:
2024-01-30 07:23:27,749:INFO:    python: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]
2024-01-30 07:23:27,749:INFO:executable: /home/zinger/miniconda3/bin/python
2024-01-30 07:23:27,749:INFO:   machine: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 07:23:27,749:INFO:PyCaret required dependencies:
2024-01-30 07:23:27,749:INFO:                 pip: 23.0.1
2024-01-30 07:23:27,749:INFO:          setuptools: 66.1.1
2024-01-30 07:23:27,749:INFO:             pycaret: 3.2.0
2024-01-30 07:23:27,749:INFO:             IPython: 8.12.2
2024-01-30 07:23:27,749:INFO:          ipywidgets: 8.1.1
2024-01-30 07:23:27,749:INFO:                tqdm: 4.65.0
2024-01-30 07:23:27,750:INFO:               numpy: 1.25.2
2024-01-30 07:23:27,750:INFO:              pandas: 1.5.3
2024-01-30 07:23:27,750:INFO:              jinja2: 3.1.2
2024-01-30 07:23:27,750:INFO:               scipy: 1.10.1
2024-01-30 07:23:27,750:INFO:              joblib: 1.3.1
2024-01-30 07:23:27,750:INFO:             sklearn: 1.2.2
2024-01-30 07:23:27,750:INFO:                pyod: 1.1.2
2024-01-30 07:23:27,750:INFO:            imblearn: 0.11.0
2024-01-30 07:23:27,750:INFO:   category_encoders: 2.6.3
2024-01-30 07:23:27,750:INFO:            lightgbm: 4.1.0
2024-01-30 07:23:27,750:INFO:               numba: 0.58.1
2024-01-30 07:23:27,750:INFO:            requests: 2.31.0
2024-01-30 07:23:27,750:INFO:          matplotlib: 3.6.0
2024-01-30 07:23:27,750:INFO:          scikitplot: 0.3.7
2024-01-30 07:23:27,750:INFO:         yellowbrick: 1.5
2024-01-30 07:23:27,750:INFO:              plotly: 5.9.0
2024-01-30 07:23:27,750:INFO:    plotly-resampler: Not installed
2024-01-30 07:23:27,750:INFO:             kaleido: 0.2.1
2024-01-30 07:23:27,750:INFO:           schemdraw: 0.15
2024-01-30 07:23:27,750:INFO:         statsmodels: 0.14.0
2024-01-30 07:23:27,750:INFO:              sktime: 0.21.1
2024-01-30 07:23:27,750:INFO:               tbats: 1.1.3
2024-01-30 07:23:27,750:INFO:            pmdarima: 2.0.4
2024-01-30 07:23:27,750:INFO:              psutil: 5.9.6
2024-01-30 07:23:27,750:INFO:          markupsafe: 2.1.1
2024-01-30 07:23:27,750:INFO:             pickle5: Not installed
2024-01-30 07:23:27,750:INFO:         cloudpickle: 2.2.1
2024-01-30 07:23:27,750:INFO:         deprecation: 2.1.0
2024-01-30 07:23:27,750:INFO:              xxhash: 3.4.1
2024-01-30 07:23:27,750:INFO:           wurlitzer: 3.0.3
2024-01-30 07:23:27,750:INFO:PyCaret optional dependencies:
2024-01-30 07:23:27,750:INFO:                shap: 0.44.0
2024-01-30 07:23:27,750:INFO:           interpret: Not installed
2024-01-30 07:23:27,750:INFO:                umap: Not installed
2024-01-30 07:23:27,750:INFO:     ydata_profiling: 4.6.2
2024-01-30 07:23:27,750:INFO:  explainerdashboard: Not installed
2024-01-30 07:23:27,750:INFO:             autoviz: Not installed
2024-01-30 07:23:27,751:INFO:           fairlearn: Not installed
2024-01-30 07:23:27,751:INFO:          deepchecks: Not installed
2024-01-30 07:23:27,751:INFO:             xgboost: Not installed
2024-01-30 07:23:27,751:INFO:            catboost: Not installed
2024-01-30 07:23:27,751:INFO:              kmodes: Not installed
2024-01-30 07:23:27,751:INFO:             mlxtend: Not installed
2024-01-30 07:23:27,751:INFO:       statsforecast: Not installed
2024-01-30 07:23:27,751:INFO:        tune_sklearn: Not installed
2024-01-30 07:23:27,751:INFO:                 ray: Not installed
2024-01-30 07:23:27,751:INFO:            hyperopt: Not installed
2024-01-30 07:23:27,751:INFO:              optuna: Not installed
2024-01-30 07:23:27,751:INFO:               skopt: 0.9.0
2024-01-30 07:23:27,751:INFO:              mlflow: 2.8.1
2024-01-30 07:23:27,751:INFO:              gradio: Not installed
2024-01-30 07:23:27,751:INFO:             fastapi: Not installed
2024-01-30 07:23:27,751:INFO:             uvicorn: Not installed
2024-01-30 07:23:27,751:INFO:              m2cgen: Not installed
2024-01-30 07:23:27,751:INFO:           evidently: Not installed
2024-01-30 07:23:27,751:INFO:               fugue: Not installed
2024-01-30 07:23:27,751:INFO:           streamlit: 1.28.2
2024-01-30 07:23:27,751:INFO:             prophet: Not installed
2024-01-30 07:23:27,751:INFO:None
2024-01-30 07:23:27,751:INFO:Set up GPU usage.
2024-01-30 07:23:27,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:27,751:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-01-30 07:23:27,751:INFO:Set up data.
2024-01-30 07:23:27,821:INFO:Set up folding strategy.
2024-01-30 07:23:27,821:INFO:Set up train/test split.
2024-01-30 07:23:27,958:INFO:Set up index.
2024-01-30 07:23:27,961:INFO:Assigning column types.
2024-01-30 07:23:27,971:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-30 07:23:27,971:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 07:23:28,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,008:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 07:23:28,008:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,025:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,029:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 07:23:28,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,287:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 07:23:28,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,392:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-30 07:23:28,392:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,425:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 07:23:28,426:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,570:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,571:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 07:23:28,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,590:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,675:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-30 07:23:28,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,815:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:28,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:28,960:INFO:Preparing preprocessing pipeline...
2024-01-30 07:23:28,963:INFO:Set up simple imputation.
2024-01-30 07:23:28,977:INFO:Set up encoding of categorical features.
2024-01-30 07:23:29,390:INFO:Finished creating preprocessing pipeline.
2024-01-30 07:23:29,397:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 07:23:29,397:INFO:Creating final display dataframe.
2024-01-30 07:23:30,040:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment           MlflowLogger
20              Experiment Name  Baseline_model_exp_02
21                          USI                   4dec
2024-01-30 07:23:30,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,100:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:30,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:30,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,252:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 07:23:30,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:30,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 07:23:30,342:INFO:Logging experiment in loggers
2024-01-30 07:23:30,652:INFO:SubProcess save_model() called ==================================
2024-01-30 07:23:30,661:INFO:Initializing save_model()
2024-01-30 07:23:30,661:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmp5h96c4rb/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-01-30 07:23:30,661:INFO:Adding model into prep_pipe
2024-01-30 07:23:30,661:WARNING:Only Model saved as it was a pipeline.
2024-01-30 07:23:30,665:INFO:/tmp/tmp5h96c4rb/Transformation Pipeline.pkl saved in current working directory
2024-01-30 07:23:30,669:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 07:23:30,669:INFO:save_model() successfully completed......................................
2024-01-30 07:23:30,754:INFO:SubProcess save_model() end ==================================
2024-01-30 07:23:31,239:INFO:setup() successfully completed in 2.62s...............
2024-01-30 07:23:47,549:INFO:Initializing compare_models()
2024-01-30 07:23:47,550:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-01-30 07:23:47,550:INFO:Checking exceptions
2024-01-30 07:23:47,569:INFO:Preparing display monitor
2024-01-30 07:23:47,596:INFO:Initializing Logistic Regression
2024-01-30 07:23:47,597:INFO:Total runtime is 4.1405359903971355e-06 minutes
2024-01-30 07:23:47,600:INFO:SubProcess create_model() called ==================================
2024-01-30 07:23:47,601:INFO:Initializing create_model()
2024-01-30 07:23:47,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:23:47,601:INFO:Checking exceptions
2024-01-30 07:23:47,601:INFO:Importing libraries
2024-01-30 07:23:47,601:INFO:Copying training dataset
2024-01-30 07:23:47,637:INFO:Defining folds
2024-01-30 07:23:47,637:INFO:Declaring metric variables
2024-01-30 07:23:47,640:INFO:Importing untrained model
2024-01-30 07:23:47,644:INFO:Logistic Regression Imported successfully
2024-01-30 07:23:47,651:INFO:Starting cross validation
2024-01-30 07:23:47,653:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:24:08,469:INFO:Calculating mean and std
2024-01-30 07:24:08,470:INFO:Creating metrics dataframe
2024-01-30 07:24:08,474:INFO:Uploading results into container
2024-01-30 07:24:08,475:INFO:Uploading model into container now
2024-01-30 07:24:08,475:INFO:_master_model_container: 1
2024-01-30 07:24:08,475:INFO:_display_container: 2
2024-01-30 07:24:08,475:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-30 07:24:08,476:INFO:create_model() successfully completed......................................
2024-01-30 07:24:08,564:INFO:SubProcess create_model() end ==================================
2024-01-30 07:24:08,564:INFO:Creating metrics dataframe
2024-01-30 07:24:08,574:INFO:Initializing Naive Bayes
2024-01-30 07:24:08,575:INFO:Total runtime is 0.3496350248654683 minutes
2024-01-30 07:24:08,579:INFO:SubProcess create_model() called ==================================
2024-01-30 07:24:08,579:INFO:Initializing create_model()
2024-01-30 07:24:08,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:24:08,579:INFO:Checking exceptions
2024-01-30 07:24:08,579:INFO:Importing libraries
2024-01-30 07:24:08,579:INFO:Copying training dataset
2024-01-30 07:24:08,622:INFO:Defining folds
2024-01-30 07:24:08,623:INFO:Declaring metric variables
2024-01-30 07:24:08,626:INFO:Importing untrained model
2024-01-30 07:24:08,630:INFO:Naive Bayes Imported successfully
2024-01-30 07:24:08,639:INFO:Starting cross validation
2024-01-30 07:24:08,640:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:24:11,782:INFO:Calculating mean and std
2024-01-30 07:24:11,783:INFO:Creating metrics dataframe
2024-01-30 07:24:11,786:INFO:Uploading results into container
2024-01-30 07:24:11,786:INFO:Uploading model into container now
2024-01-30 07:24:11,786:INFO:_master_model_container: 2
2024-01-30 07:24:11,786:INFO:_display_container: 2
2024-01-30 07:24:11,787:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-30 07:24:11,787:INFO:create_model() successfully completed......................................
2024-01-30 07:24:11,871:INFO:SubProcess create_model() end ==================================
2024-01-30 07:24:11,871:INFO:Creating metrics dataframe
2024-01-30 07:24:11,880:INFO:Initializing Decision Tree Classifier
2024-01-30 07:24:11,881:INFO:Total runtime is 0.40473432143529253 minutes
2024-01-30 07:24:11,884:INFO:SubProcess create_model() called ==================================
2024-01-30 07:24:11,885:INFO:Initializing create_model()
2024-01-30 07:24:11,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:24:11,885:INFO:Checking exceptions
2024-01-30 07:24:11,885:INFO:Importing libraries
2024-01-30 07:24:11,885:INFO:Copying training dataset
2024-01-30 07:24:11,931:INFO:Defining folds
2024-01-30 07:24:11,931:INFO:Declaring metric variables
2024-01-30 07:24:11,937:INFO:Importing untrained model
2024-01-30 07:24:11,942:INFO:Decision Tree Classifier Imported successfully
2024-01-30 07:24:11,950:INFO:Starting cross validation
2024-01-30 07:24:11,951:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:24:16,201:INFO:Calculating mean and std
2024-01-30 07:24:16,202:INFO:Creating metrics dataframe
2024-01-30 07:24:16,206:INFO:Uploading results into container
2024-01-30 07:24:16,206:INFO:Uploading model into container now
2024-01-30 07:24:16,206:INFO:_master_model_container: 3
2024-01-30 07:24:16,206:INFO:_display_container: 2
2024-01-30 07:24:16,207:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2024-01-30 07:24:16,207:INFO:create_model() successfully completed......................................
2024-01-30 07:24:16,289:INFO:SubProcess create_model() end ==================================
2024-01-30 07:24:16,289:INFO:Creating metrics dataframe
2024-01-30 07:24:16,298:INFO:Initializing Ridge Classifier
2024-01-30 07:24:16,298:INFO:Total runtime is 0.4783560037612915 minutes
2024-01-30 07:24:16,301:INFO:SubProcess create_model() called ==================================
2024-01-30 07:24:16,301:INFO:Initializing create_model()
2024-01-30 07:24:16,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:24:16,301:INFO:Checking exceptions
2024-01-30 07:24:16,301:INFO:Importing libraries
2024-01-30 07:24:16,301:INFO:Copying training dataset
2024-01-30 07:24:16,340:INFO:Defining folds
2024-01-30 07:24:16,340:INFO:Declaring metric variables
2024-01-30 07:24:16,343:INFO:Importing untrained model
2024-01-30 07:24:16,347:INFO:Ridge Classifier Imported successfully
2024-01-30 07:24:16,354:INFO:Starting cross validation
2024-01-30 07:24:16,355:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:24:19,911:INFO:Calculating mean and std
2024-01-30 07:24:19,912:INFO:Creating metrics dataframe
2024-01-30 07:24:19,915:INFO:Uploading results into container
2024-01-30 07:24:19,916:INFO:Uploading model into container now
2024-01-30 07:24:19,916:INFO:_master_model_container: 4
2024-01-30 07:24:19,916:INFO:_display_container: 2
2024-01-30 07:24:19,916:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-01-30 07:24:19,916:INFO:create_model() successfully completed......................................
2024-01-30 07:24:20,002:INFO:SubProcess create_model() end ==================================
2024-01-30 07:24:20,002:INFO:Creating metrics dataframe
2024-01-30 07:24:20,011:INFO:Initializing Random Forest Classifier
2024-01-30 07:24:20,012:INFO:Total runtime is 0.540251100063324 minutes
2024-01-30 07:24:20,015:INFO:SubProcess create_model() called ==================================
2024-01-30 07:24:20,016:INFO:Initializing create_model()
2024-01-30 07:24:20,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:24:20,016:INFO:Checking exceptions
2024-01-30 07:24:20,016:INFO:Importing libraries
2024-01-30 07:24:20,016:INFO:Copying training dataset
2024-01-30 07:24:20,046:INFO:Defining folds
2024-01-30 07:24:20,046:INFO:Declaring metric variables
2024-01-30 07:24:20,049:INFO:Importing untrained model
2024-01-30 07:24:20,054:INFO:Random Forest Classifier Imported successfully
2024-01-30 07:24:20,059:INFO:Starting cross validation
2024-01-30 07:24:20,061:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:24:47,252:INFO:Calculating mean and std
2024-01-30 07:24:47,253:INFO:Creating metrics dataframe
2024-01-30 07:24:47,256:INFO:Uploading results into container
2024-01-30 07:24:47,256:INFO:Uploading model into container now
2024-01-30 07:24:47,257:INFO:_master_model_container: 5
2024-01-30 07:24:47,257:INFO:_display_container: 2
2024-01-30 07:24:47,257:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2024-01-30 07:24:47,257:INFO:create_model() successfully completed......................................
2024-01-30 07:24:47,342:INFO:SubProcess create_model() end ==================================
2024-01-30 07:24:47,342:INFO:Creating metrics dataframe
2024-01-30 07:24:47,351:INFO:Initializing Linear Discriminant Analysis
2024-01-30 07:24:47,351:INFO:Total runtime is 0.9959119240442912 minutes
2024-01-30 07:24:47,354:INFO:SubProcess create_model() called ==================================
2024-01-30 07:24:47,355:INFO:Initializing create_model()
2024-01-30 07:24:47,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:24:47,355:INFO:Checking exceptions
2024-01-30 07:24:47,355:INFO:Importing libraries
2024-01-30 07:24:47,355:INFO:Copying training dataset
2024-01-30 07:24:47,391:INFO:Defining folds
2024-01-30 07:24:47,391:INFO:Declaring metric variables
2024-01-30 07:24:47,394:INFO:Importing untrained model
2024-01-30 07:24:47,398:INFO:Linear Discriminant Analysis Imported successfully
2024-01-30 07:24:47,405:INFO:Starting cross validation
2024-01-30 07:24:47,407:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:24:53,138:INFO:Calculating mean and std
2024-01-30 07:24:53,139:INFO:Creating metrics dataframe
2024-01-30 07:24:53,142:INFO:Uploading results into container
2024-01-30 07:24:53,143:INFO:Uploading model into container now
2024-01-30 07:24:53,144:INFO:_master_model_container: 6
2024-01-30 07:24:53,144:INFO:_display_container: 2
2024-01-30 07:24:53,145:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-30 07:24:53,145:INFO:create_model() successfully completed......................................
2024-01-30 07:24:53,230:INFO:SubProcess create_model() end ==================================
2024-01-30 07:24:53,230:INFO:Creating metrics dataframe
2024-01-30 07:24:53,240:INFO:Initializing Extra Trees Classifier
2024-01-30 07:24:53,240:INFO:Total runtime is 1.094056244691213 minutes
2024-01-30 07:24:53,243:INFO:SubProcess create_model() called ==================================
2024-01-30 07:24:53,243:INFO:Initializing create_model()
2024-01-30 07:24:53,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:24:53,243:INFO:Checking exceptions
2024-01-30 07:24:53,243:INFO:Importing libraries
2024-01-30 07:24:53,243:INFO:Copying training dataset
2024-01-30 07:24:53,280:INFO:Defining folds
2024-01-30 07:24:53,281:INFO:Declaring metric variables
2024-01-30 07:24:53,283:INFO:Importing untrained model
2024-01-30 07:24:53,287:INFO:Extra Trees Classifier Imported successfully
2024-01-30 07:24:53,294:INFO:Starting cross validation
2024-01-30 07:24:53,295:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:25:23,562:INFO:Calculating mean and std
2024-01-30 07:25:23,563:INFO:Creating metrics dataframe
2024-01-30 07:25:23,568:INFO:Uploading results into container
2024-01-30 07:25:23,569:INFO:Uploading model into container now
2024-01-30 07:25:23,569:INFO:_master_model_container: 7
2024-01-30 07:25:23,569:INFO:_display_container: 2
2024-01-30 07:25:23,569:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2024-01-30 07:25:23,569:INFO:create_model() successfully completed......................................
2024-01-30 07:25:23,656:INFO:SubProcess create_model() end ==================================
2024-01-30 07:25:23,656:INFO:Creating metrics dataframe
2024-01-30 07:25:23,666:INFO:Initializing Light Gradient Boosting Machine
2024-01-30 07:25:23,666:INFO:Total runtime is 1.601162314414978 minutes
2024-01-30 07:25:23,669:INFO:SubProcess create_model() called ==================================
2024-01-30 07:25:23,669:INFO:Initializing create_model()
2024-01-30 07:25:23,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f86d13beb30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:25:23,669:INFO:Checking exceptions
2024-01-30 07:25:23,669:INFO:Importing libraries
2024-01-30 07:25:23,669:INFO:Copying training dataset
2024-01-30 07:25:23,707:INFO:Defining folds
2024-01-30 07:25:23,707:INFO:Declaring metric variables
2024-01-30 07:25:23,710:INFO:Importing untrained model
2024-01-30 07:25:23,714:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 07:25:23,723:INFO:Starting cross validation
2024-01-30 07:25:23,724:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 07:25:24,220:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 07:25:24,220:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 07:25:24,221:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 07:25:24,221:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 07:25:24,298:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 07:25:24,298:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 07:25:24,314:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 07:25:24,316:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 07:25:24,317:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001444 secs. 1 sparse feature groups
2024-01-30 07:25:24,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 07:25:24,318:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 07:25:25,717:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 07:25:25,717:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 07:25:25,718:INFO:[LightGBM] [Info] Total Bins 114
2024-01-30 07:25:25,718:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 07:25:25,772:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 07:25:25,772:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 07:25:25,785:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 07:25:25,786:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 07:25:25,789:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.002761 secs. 1 sparse feature groups
2024-01-30 07:25:25,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 07:25:25,791:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 07:25:27,055:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 07:25:27,055:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 07:25:27,056:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 07:25:27,056:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 07:25:27,102:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 07:25:27,103:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 07:25:27,108:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 07:25:27,109:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 07:25:27,131:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.022042 secs. 1 sparse feature groups
2024-01-30 07:25:27,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 07:25:27,132:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 07:25:28,419:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 07:25:28,419:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 07:25:28,420:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 07:25:28,420:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 07:25:28,466:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 07:25:28,466:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 07:25:28,471:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 07:25:28,472:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 07:25:28,474:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001566 secs. 1 sparse feature groups
2024-01-30 07:25:28,474:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 07:25:28,474:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 07:25:29,800:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 07:25:29,800:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 07:25:29,801:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 07:25:29,801:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 38
2024-01-30 07:25:29,848:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 07:25:29,848:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 07:25:29,854:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 07:25:29,855:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 07:25:29,857:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001707 secs. 1 sparse feature groups
2024-01-30 07:25:29,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 07:25:29,858:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 07:25:30,588:INFO:Calculating mean and std
2024-01-30 07:25:30,589:INFO:Creating metrics dataframe
2024-01-30 07:25:30,593:INFO:Uploading results into container
2024-01-30 07:25:30,594:INFO:Uploading model into container now
2024-01-30 07:25:30,595:INFO:_master_model_container: 8
2024-01-30 07:25:30,595:INFO:_display_container: 2
2024-01-30 07:25:30,595:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 07:25:30,595:INFO:create_model() successfully completed......................................
2024-01-30 07:25:30,679:INFO:SubProcess create_model() end ==================================
2024-01-30 07:25:30,679:INFO:Creating metrics dataframe
2024-01-30 07:25:30,697:INFO:Initializing create_model()
2024-01-30 07:25:30,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 07:25:30,698:INFO:Checking exceptions
2024-01-30 07:25:30,700:INFO:Importing libraries
2024-01-30 07:25:30,700:INFO:Copying training dataset
2024-01-30 07:25:30,740:INFO:Defining folds
2024-01-30 07:25:30,740:INFO:Declaring metric variables
2024-01-30 07:25:30,741:INFO:Importing untrained model
2024-01-30 07:25:30,741:INFO:Declaring custom model
2024-01-30 07:25:30,741:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 07:25:30,742:INFO:Cross validation set to False
2024-01-30 07:25:30,742:INFO:Fitting Model
2024-01-30 07:25:31,367:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 07:25:31,368:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 07:25:31,369:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 07:25:31,369:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 38
2024-01-30 07:25:31,418:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 07:25:31,418:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 07:25:31,423:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 07:25:31,425:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 07:25:31,434:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.009027 secs. 1 sparse feature groups
2024-01-30 07:25:31,434:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 07:25:31,434:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 07:25:32,209:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 07:25:32,209:INFO:create_model() successfully completed......................................
2024-01-30 07:25:32,295:INFO:Creating Dashboard logs
2024-01-30 07:25:32,300:INFO:Model: Light Gradient Boosting Machine
2024-01-30 07:25:32,344:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 07:25:32,668:INFO:Initializing predict_model()
2024-01-30 07:25:32,668:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f86cb376f80>)
2024-01-30 07:25:32,668:INFO:Checking exceptions
2024-01-30 07:25:32,668:INFO:Preloading libraries
2024-01-30 07:25:33,155:INFO:SubProcess plot_model() called ==================================
2024-01-30 07:25:33,155:INFO:Initializing plot_model()
2024-01-30 07:25:33,155:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp4xpvwmh7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, system=False)
2024-01-30 07:25:33,155:INFO:Checking exceptions
2024-01-30 07:25:33,168:INFO:Preloading libraries
2024-01-30 07:25:33,172:INFO:Copying training dataset
2024-01-30 07:25:33,172:INFO:Plot type: auc
2024-01-30 07:25:33,394:INFO:Fitting Model
2024-01-30 07:25:33,400:INFO:Scoring test/hold-out set
2024-01-30 07:25:33,615:INFO:Saving '/tmp/tmp4xpvwmh7/AUC.png'
2024-01-30 07:25:33,788:INFO:Visual Rendered Successfully
2024-01-30 07:25:33,873:INFO:plot_model() successfully completed......................................
2024-01-30 07:25:33,874:INFO:Initializing plot_model()
2024-01-30 07:25:33,874:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp4xpvwmh7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, system=False)
2024-01-30 07:25:33,874:INFO:Checking exceptions
2024-01-30 07:25:33,886:INFO:Preloading libraries
2024-01-30 07:25:33,889:INFO:Copying training dataset
2024-01-30 07:25:33,889:INFO:Plot type: confusion_matrix
2024-01-30 07:25:34,101:INFO:Fitting Model
2024-01-30 07:25:34,103:INFO:Scoring test/hold-out set
2024-01-30 07:25:34,245:INFO:Saving '/tmp/tmp4xpvwmh7/Confusion Matrix.png'
2024-01-30 07:25:34,328:INFO:Visual Rendered Successfully
2024-01-30 07:25:34,407:INFO:plot_model() successfully completed......................................
2024-01-30 07:25:34,408:INFO:Initializing plot_model()
2024-01-30 07:25:34,408:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp4xpvwmh7, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, system=False)
2024-01-30 07:25:34,408:INFO:Checking exceptions
2024-01-30 07:25:34,419:INFO:Preloading libraries
2024-01-30 07:25:34,422:INFO:Copying training dataset
2024-01-30 07:25:34,422:INFO:Plot type: feature
2024-01-30 07:25:34,432:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 07:25:34,511:INFO:Saving '/tmp/tmp4xpvwmh7/Feature Importance.png'
2024-01-30 07:25:34,643:INFO:Visual Rendered Successfully
2024-01-30 07:25:34,728:INFO:plot_model() successfully completed......................................
2024-01-30 07:25:34,728:INFO:SubProcess plot_model() end ==================================
2024-01-30 07:25:34,904:INFO:Creating Dashboard logs
2024-01-30 07:25:34,907:INFO:Model: Random Forest Classifier
2024-01-30 07:25:34,949:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 07:25:35,395:INFO:Creating Dashboard logs
2024-01-30 07:25:35,398:INFO:Model: Extra Trees Classifier
2024-01-30 07:25:35,439:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 07:25:35,893:INFO:Creating Dashboard logs
2024-01-30 07:25:35,895:INFO:Model: Decision Tree Classifier
2024-01-30 07:25:35,933:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2024-01-30 07:25:36,374:INFO:Creating Dashboard logs
2024-01-30 07:25:36,377:INFO:Model: Logistic Regression
2024-01-30 07:25:36,416:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-01-30 07:25:36,838:INFO:Creating Dashboard logs
2024-01-30 07:25:36,841:INFO:Model: Ridge Classifier
2024-01-30 07:25:36,881:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2024-01-30 07:25:37,333:INFO:Creating Dashboard logs
2024-01-30 07:25:37,335:INFO:Model: Linear Discriminant Analysis
2024-01-30 07:25:37,378:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-01-30 07:25:37,850:INFO:Creating Dashboard logs
2024-01-30 07:25:37,853:INFO:Model: Naive Bayes
2024-01-30 07:25:37,892:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-01-30 07:25:38,434:INFO:_master_model_container: 8
2024-01-30 07:25:38,434:INFO:_display_container: 2
2024-01-30 07:25:38,435:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 07:25:38,435:INFO:compare_models() successfully completed......................................
2024-01-30 08:25:40,195:INFO:Initializing create_model()
2024-01-30 08:25:40,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:25:40,196:INFO:Checking exceptions
2024-01-30 08:25:40,212:INFO:Importing libraries
2024-01-30 08:25:40,212:INFO:Copying training dataset
2024-01-30 08:25:40,276:INFO:Defining folds
2024-01-30 08:25:40,276:INFO:Declaring metric variables
2024-01-30 08:25:40,279:INFO:Importing untrained model
2024-01-30 08:25:40,285:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 08:25:40,296:INFO:Starting cross validation
2024-01-30 08:25:40,298:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:25:40,786:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:25:40,787:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:25:40,787:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 08:25:40,788:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:25:40,853:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:25:40,853:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:25:40,858:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:25:40,859:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:25:40,862:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001726 secs. 1 sparse feature groups
2024-01-30 08:25:40,862:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:25:40,865:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:25:42,293:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:25:42,294:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:25:42,295:INFO:[LightGBM] [Info] Total Bins 114
2024-01-30 08:25:42,295:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:25:42,343:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:25:42,343:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:25:42,347:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:25:42,349:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:25:42,350:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001458 secs. 1 sparse feature groups
2024-01-30 08:25:42,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:25:42,351:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:25:43,695:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:25:43,696:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:25:43,696:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:25:43,697:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:25:43,744:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:25:43,744:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:25:43,753:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:25:43,755:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:25:43,757:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001504 secs. 1 sparse feature groups
2024-01-30 08:25:43,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:25:43,758:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:25:44,966:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 08:25:44,966:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:25:44,967:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:25:44,967:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:25:45,018:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:25:45,018:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:25:45,030:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:25:45,032:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:25:45,078:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.045511 secs. 1 sparse feature groups
2024-01-30 08:25:45,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 08:25:45,079:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 08:25:46,330:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 08:25:46,330:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:25:46,332:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:25:46,333:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 38
2024-01-30 08:25:46,388:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:25:46,388:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:25:46,393:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:25:46,394:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:25:46,396:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001634 secs. 1 sparse feature groups
2024-01-30 08:25:46,397:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 08:25:46,397:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 08:25:47,126:INFO:Calculating mean and std
2024-01-30 08:25:47,127:INFO:Creating metrics dataframe
2024-01-30 08:25:47,132:INFO:Finalizing model
2024-01-30 08:25:47,710:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 08:25:47,710:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:25:47,711:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 08:25:47,712:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 38
2024-01-30 08:25:47,769:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:25:47,770:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:25:47,776:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:25:47,777:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:25:47,814:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.036481 secs. 1 sparse feature groups
2024-01-30 08:25:47,816:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 08:25:47,816:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 08:25:48,554:INFO:Creating Dashboard logs
2024-01-30 08:25:48,559:INFO:Model: Light Gradient Boosting Machine
2024-01-30 08:25:48,611:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 08:25:48,908:INFO:Initializing predict_model()
2024-01-30 08:25:48,908:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f86d14969e0>)
2024-01-30 08:25:48,908:INFO:Checking exceptions
2024-01-30 08:25:48,908:INFO:Preloading libraries
2024-01-30 08:25:49,367:INFO:SubProcess plot_model() called ==================================
2024-01-30 08:25:49,368:INFO:Initializing plot_model()
2024-01-30 08:25:49,368:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmptigab5zp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, system=False)
2024-01-30 08:25:49,368:INFO:Checking exceptions
2024-01-30 08:25:49,378:INFO:Preloading libraries
2024-01-30 08:25:49,381:INFO:Copying training dataset
2024-01-30 08:25:49,381:INFO:Plot type: auc
2024-01-30 08:25:49,569:INFO:Fitting Model
2024-01-30 08:25:49,573:INFO:Scoring test/hold-out set
2024-01-30 08:25:49,802:INFO:Saving '/tmp/tmptigab5zp/AUC.png'
2024-01-30 08:25:49,966:INFO:Visual Rendered Successfully
2024-01-30 08:25:50,053:INFO:plot_model() successfully completed......................................
2024-01-30 08:25:50,054:INFO:Initializing plot_model()
2024-01-30 08:25:50,055:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmptigab5zp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, system=False)
2024-01-30 08:25:50,055:INFO:Checking exceptions
2024-01-30 08:25:50,065:INFO:Preloading libraries
2024-01-30 08:25:50,090:INFO:Copying training dataset
2024-01-30 08:25:50,090:INFO:Plot type: confusion_matrix
2024-01-30 08:25:50,310:INFO:Fitting Model
2024-01-30 08:25:50,312:INFO:Scoring test/hold-out set
2024-01-30 08:25:50,496:INFO:Saving '/tmp/tmptigab5zp/Confusion Matrix.png'
2024-01-30 08:25:50,603:INFO:Visual Rendered Successfully
2024-01-30 08:25:50,689:INFO:plot_model() successfully completed......................................
2024-01-30 08:25:50,690:INFO:Initializing plot_model()
2024-01-30 08:25:50,690:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmptigab5zp, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>, system=False)
2024-01-30 08:25:50,690:INFO:Checking exceptions
2024-01-30 08:25:50,698:INFO:Preloading libraries
2024-01-30 08:25:50,702:INFO:Copying training dataset
2024-01-30 08:25:50,702:INFO:Plot type: feature
2024-01-30 08:25:50,712:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 08:25:50,800:INFO:Saving '/tmp/tmptigab5zp/Feature Importance.png'
2024-01-30 08:25:50,943:INFO:Visual Rendered Successfully
2024-01-30 08:25:51,026:INFO:plot_model() successfully completed......................................
2024-01-30 08:25:51,027:INFO:SubProcess plot_model() end ==================================
2024-01-30 08:25:51,201:INFO:Uploading results into container
2024-01-30 08:25:51,202:INFO:Uploading model into container now
2024-01-30 08:25:51,211:INFO:_master_model_container: 9
2024-01-30 08:25:51,212:INFO:_display_container: 3
2024-01-30 08:25:51,212:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:25:51,212:INFO:create_model() successfully completed......................................
2024-01-30 08:26:13,445:INFO:Initializing tune_model()
2024-01-30 08:26:13,445:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=100, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f86d1487250>)
2024-01-30 08:26:13,446:INFO:Checking exceptions
2024-01-30 08:26:13,446:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2024-01-30 08:27:12,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:12,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:12,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:12,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:13,504:INFO:PyCaret ClassificationExperiment
2024-01-30 08:27:13,505:INFO:Logging name: Baseline_model_exp_01
2024-01-30 08:27:13,505:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-30 08:27:13,505:INFO:version 3.2.0
2024-01-30 08:27:13,505:INFO:Initializing setup()
2024-01-30 08:27:13,505:INFO:self.USI: ed20
2024-01-30 08:27:13,505:INFO:self._variable_keys: {'pipeline', 'n_jobs_param', 'target_param', 'data', 'memory', 'gpu_n_jobs_param', 'y', 'X', 'y_train', 'X_test', 'y_test', 'fix_imbalance', 'USI', 'is_multiclass', 'seed', 'exp_id', 'exp_name_log', 'fold_shuffle_param', 'idx', 'html_param', 'gpu_param', 'logging_param', '_ml_usecase', 'fold_generator', 'fold_groups_param', 'log_plots_param', '_available_plots', 'X_train'}
2024-01-30 08:27:13,505:INFO:Checking environment
2024-01-30 08:27:13,505:INFO:python_version: 3.10.12
2024-01-30 08:27:13,505:INFO:python_build: ('main', 'Jul  5 2023 18:54:27')
2024-01-30 08:27:13,505:INFO:machine: x86_64
2024-01-30 08:27:13,506:INFO:platform: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 08:27:13,506:INFO:Memory: svmem(total=67274690560, available=58915438592, percent=12.4, used=6379634688, free=48077594624, active=10018578432, inactive=6224506880, buffers=4120576, cached=12813340672, shared=1139605504, slab=2218721280)
2024-01-30 08:27:13,506:INFO:Physical Core: 4
2024-01-30 08:27:13,507:INFO:Logical Core: 8
2024-01-30 08:27:13,507:INFO:Checking libraries
2024-01-30 08:27:13,507:INFO:System:
2024-01-30 08:27:13,507:INFO:    python: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]
2024-01-30 08:27:13,507:INFO:executable: /home/zinger/miniconda3/bin/python
2024-01-30 08:27:13,507:INFO:   machine: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 08:27:13,507:INFO:PyCaret required dependencies:
2024-01-30 08:27:13,841:INFO:                 pip: 23.0.1
2024-01-30 08:27:13,841:INFO:          setuptools: 66.1.1
2024-01-30 08:27:13,841:INFO:             pycaret: 3.2.0
2024-01-30 08:27:13,841:INFO:             IPython: 8.12.2
2024-01-30 08:27:13,841:INFO:          ipywidgets: 8.1.1
2024-01-30 08:27:13,841:INFO:                tqdm: 4.65.0
2024-01-30 08:27:13,841:INFO:               numpy: 1.25.2
2024-01-30 08:27:13,841:INFO:              pandas: 1.5.3
2024-01-30 08:27:13,841:INFO:              jinja2: 3.1.2
2024-01-30 08:27:13,841:INFO:               scipy: 1.10.1
2024-01-30 08:27:13,841:INFO:              joblib: 1.3.1
2024-01-30 08:27:13,841:INFO:             sklearn: 1.2.2
2024-01-30 08:27:13,841:INFO:                pyod: 1.1.2
2024-01-30 08:27:13,841:INFO:            imblearn: 0.11.0
2024-01-30 08:27:13,841:INFO:   category_encoders: 2.6.3
2024-01-30 08:27:13,841:INFO:            lightgbm: 4.1.0
2024-01-30 08:27:13,841:INFO:               numba: 0.58.1
2024-01-30 08:27:13,841:INFO:            requests: 2.31.0
2024-01-30 08:27:13,841:INFO:          matplotlib: 3.6.0
2024-01-30 08:27:13,841:INFO:          scikitplot: 0.3.7
2024-01-30 08:27:13,841:INFO:         yellowbrick: 1.5
2024-01-30 08:27:13,841:INFO:              plotly: 5.9.0
2024-01-30 08:27:13,841:INFO:    plotly-resampler: Not installed
2024-01-30 08:27:13,842:INFO:             kaleido: 0.2.1
2024-01-30 08:27:13,842:INFO:           schemdraw: 0.15
2024-01-30 08:27:13,842:INFO:         statsmodels: 0.14.0
2024-01-30 08:27:13,842:INFO:              sktime: 0.21.1
2024-01-30 08:27:13,842:INFO:               tbats: 1.1.3
2024-01-30 08:27:13,842:INFO:            pmdarima: 2.0.4
2024-01-30 08:27:13,842:INFO:              psutil: 5.9.6
2024-01-30 08:27:13,842:INFO:          markupsafe: 2.1.1
2024-01-30 08:27:13,842:INFO:             pickle5: Not installed
2024-01-30 08:27:13,842:INFO:         cloudpickle: 2.2.1
2024-01-30 08:27:13,842:INFO:         deprecation: 2.1.0
2024-01-30 08:27:13,842:INFO:              xxhash: 3.4.1
2024-01-30 08:27:13,842:INFO:           wurlitzer: 3.0.3
2024-01-30 08:27:13,842:INFO:PyCaret optional dependencies:
2024-01-30 08:27:13,852:INFO:                shap: 0.44.0
2024-01-30 08:27:13,852:INFO:           interpret: Not installed
2024-01-30 08:27:13,852:INFO:                umap: Not installed
2024-01-30 08:27:13,852:INFO:     ydata_profiling: 4.6.2
2024-01-30 08:27:13,852:INFO:  explainerdashboard: Not installed
2024-01-30 08:27:13,852:INFO:             autoviz: Not installed
2024-01-30 08:27:13,852:INFO:           fairlearn: Not installed
2024-01-30 08:27:13,852:INFO:          deepchecks: Not installed
2024-01-30 08:27:13,852:INFO:             xgboost: Not installed
2024-01-30 08:27:13,852:INFO:            catboost: Not installed
2024-01-30 08:27:13,852:INFO:              kmodes: Not installed
2024-01-30 08:27:13,852:INFO:             mlxtend: Not installed
2024-01-30 08:27:13,852:INFO:       statsforecast: Not installed
2024-01-30 08:27:13,852:INFO:        tune_sklearn: Not installed
2024-01-30 08:27:13,852:INFO:                 ray: Not installed
2024-01-30 08:27:13,852:INFO:            hyperopt: Not installed
2024-01-30 08:27:13,852:INFO:              optuna: 3.5.0
2024-01-30 08:27:13,852:INFO:               skopt: 0.9.0
2024-01-30 08:27:13,852:INFO:              mlflow: 2.8.1
2024-01-30 08:27:13,853:INFO:              gradio: Not installed
2024-01-30 08:27:13,853:INFO:             fastapi: Not installed
2024-01-30 08:27:13,853:INFO:             uvicorn: Not installed
2024-01-30 08:27:13,853:INFO:              m2cgen: Not installed
2024-01-30 08:27:13,853:INFO:           evidently: Not installed
2024-01-30 08:27:13,853:INFO:               fugue: Not installed
2024-01-30 08:27:13,853:INFO:           streamlit: 1.28.2
2024-01-30 08:27:13,853:INFO:             prophet: Not installed
2024-01-30 08:27:13,853:INFO:None
2024-01-30 08:27:13,853:INFO:Set up GPU usage.
2024-01-30 08:27:13,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:13,853:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-01-30 08:27:13,853:INFO:Set up data.
2024-01-30 08:27:13,921:INFO:Set up folding strategy.
2024-01-30 08:27:13,921:INFO:Set up train/test split.
2024-01-30 08:27:13,997:INFO:Set up index.
2024-01-30 08:27:14,001:INFO:Assigning column types.
2024-01-30 08:27:14,018:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-30 08:27:14,019:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 08:27:14,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,054:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:27:14,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,250:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,250:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 08:27:14,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,288:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:27:14,288:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,395:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-30 08:27:14,395:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,433:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:27:14,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,535:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,536:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,575:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:27:14,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,690:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-30 08:27:14,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,730:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,747:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,751:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,835:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,898:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,901:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:14,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:14,985:INFO:Preparing preprocessing pipeline...
2024-01-30 08:27:14,989:INFO:Set up simple imputation.
2024-01-30 08:27:15,003:INFO:Set up encoding of categorical features.
2024-01-30 08:27:15,122:INFO:Finished creating preprocessing pipeline.
2024-01-30 08:27:15,126:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 08:27:15,126:INFO:Creating final display dataframe.
2024-01-30 08:27:15,377:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape           (238964, 12)
4        Transformed data shape           (238964, 44)
5   Transformed train set shape           (167274, 44)
6    Transformed test set shape            (71690, 44)
7              Numeric features                      8
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment           MlflowLogger
20              Experiment Name  Baseline_model_exp_01
21                          USI                   ed20
2024-01-30 08:27:15,382:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:15,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:15,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,581:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,585:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:27:15,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:15,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:27:15,682:INFO:Logging experiment in loggers
2024-01-30 08:27:16,062:INFO:SubProcess save_model() called ==================================
2024-01-30 08:27:16,070:INFO:Initializing save_model()
2024-01-30 08:27:16,070:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpygk3qtlj/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-01-30 08:27:16,070:INFO:Adding model into prep_pipe
2024-01-30 08:27:16,070:WARNING:Only Model saved as it was a pipeline.
2024-01-30 08:27:16,075:INFO:/tmp/tmpygk3qtlj/Transformation Pipeline.pkl saved in current working directory
2024-01-30 08:27:16,079:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['city_tier',
                                             'total_leads_droppped',
                                             'referred_lead',
                                             'assistance_interaction',
                                             'career_interaction',
                                             'payment_interaction',
                                             'social_interaction',
                                             'syllabus_interaction'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 08:27:16,079:INFO:save_model() successfully completed......................................
2024-01-30 08:27:16,158:INFO:SubProcess save_model() end ==================================
2024-01-30 08:27:16,924:INFO:setup() successfully completed in 2.18s...............
2024-01-30 08:27:16,940:INFO:Initializing compare_models()
2024-01-30 08:27:16,940:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-01-30 08:27:16,940:INFO:Checking exceptions
2024-01-30 08:27:16,972:INFO:Preparing display monitor
2024-01-30 08:27:16,999:INFO:Initializing Logistic Regression
2024-01-30 08:27:16,999:INFO:Total runtime is 3.862380981445312e-06 minutes
2024-01-30 08:27:17,004:INFO:SubProcess create_model() called ==================================
2024-01-30 08:27:17,004:INFO:Initializing create_model()
2024-01-30 08:27:17,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:27:17,005:INFO:Checking exceptions
2024-01-30 08:27:17,005:INFO:Importing libraries
2024-01-30 08:27:17,005:INFO:Copying training dataset
2024-01-30 08:27:17,056:INFO:Defining folds
2024-01-30 08:27:17,057:INFO:Declaring metric variables
2024-01-30 08:27:17,060:INFO:Importing untrained model
2024-01-30 08:27:17,065:INFO:Logistic Regression Imported successfully
2024-01-30 08:27:17,073:INFO:Starting cross validation
2024-01-30 08:27:17,075:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:27:52,796:INFO:Calculating mean and std
2024-01-30 08:27:52,797:INFO:Creating metrics dataframe
2024-01-30 08:27:52,801:INFO:Uploading results into container
2024-01-30 08:27:52,802:INFO:Uploading model into container now
2024-01-30 08:27:52,803:INFO:_master_model_container: 1
2024-01-30 08:27:52,803:INFO:_display_container: 2
2024-01-30 08:27:52,803:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-30 08:27:52,804:INFO:create_model() successfully completed......................................
2024-01-30 08:27:52,877:INFO:SubProcess create_model() end ==================================
2024-01-30 08:27:52,877:INFO:Creating metrics dataframe
2024-01-30 08:27:52,884:INFO:Initializing Naive Bayes
2024-01-30 08:27:52,884:INFO:Total runtime is 0.5980827371279399 minutes
2024-01-30 08:27:52,887:INFO:SubProcess create_model() called ==================================
2024-01-30 08:27:52,888:INFO:Initializing create_model()
2024-01-30 08:27:52,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:27:52,888:INFO:Checking exceptions
2024-01-30 08:27:52,888:INFO:Importing libraries
2024-01-30 08:27:52,888:INFO:Copying training dataset
2024-01-30 08:27:52,935:INFO:Defining folds
2024-01-30 08:27:52,935:INFO:Declaring metric variables
2024-01-30 08:27:52,938:INFO:Importing untrained model
2024-01-30 08:27:52,941:INFO:Naive Bayes Imported successfully
2024-01-30 08:27:52,948:INFO:Starting cross validation
2024-01-30 08:27:52,949:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:27:56,113:INFO:Calculating mean and std
2024-01-30 08:27:56,114:INFO:Creating metrics dataframe
2024-01-30 08:27:56,118:INFO:Uploading results into container
2024-01-30 08:27:56,118:INFO:Uploading model into container now
2024-01-30 08:27:56,118:INFO:_master_model_container: 2
2024-01-30 08:27:56,118:INFO:_display_container: 2
2024-01-30 08:27:56,118:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-30 08:27:56,119:INFO:create_model() successfully completed......................................
2024-01-30 08:27:56,195:INFO:SubProcess create_model() end ==================================
2024-01-30 08:27:56,195:INFO:Creating metrics dataframe
2024-01-30 08:27:56,203:INFO:Initializing Decision Tree Classifier
2024-01-30 08:27:56,204:INFO:Total runtime is 0.6534067710240683 minutes
2024-01-30 08:27:56,206:INFO:SubProcess create_model() called ==================================
2024-01-30 08:27:56,206:INFO:Initializing create_model()
2024-01-30 08:27:56,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:27:56,206:INFO:Checking exceptions
2024-01-30 08:27:56,206:INFO:Importing libraries
2024-01-30 08:27:56,206:INFO:Copying training dataset
2024-01-30 08:27:56,239:INFO:Defining folds
2024-01-30 08:27:56,240:INFO:Declaring metric variables
2024-01-30 08:27:56,242:INFO:Importing untrained model
2024-01-30 08:27:56,245:INFO:Decision Tree Classifier Imported successfully
2024-01-30 08:27:56,250:INFO:Starting cross validation
2024-01-30 08:27:56,251:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:28:00,487:INFO:Calculating mean and std
2024-01-30 08:28:00,488:INFO:Creating metrics dataframe
2024-01-30 08:28:00,490:INFO:Uploading results into container
2024-01-30 08:28:00,491:INFO:Uploading model into container now
2024-01-30 08:28:00,491:INFO:_master_model_container: 3
2024-01-30 08:28:00,491:INFO:_display_container: 2
2024-01-30 08:28:00,492:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2024-01-30 08:28:00,492:INFO:create_model() successfully completed......................................
2024-01-30 08:28:00,568:INFO:SubProcess create_model() end ==================================
2024-01-30 08:28:00,568:INFO:Creating metrics dataframe
2024-01-30 08:28:00,577:INFO:Initializing Ridge Classifier
2024-01-30 08:28:00,577:INFO:Total runtime is 0.7262995719909668 minutes
2024-01-30 08:28:00,580:INFO:SubProcess create_model() called ==================================
2024-01-30 08:28:00,581:INFO:Initializing create_model()
2024-01-30 08:28:00,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:28:00,581:INFO:Checking exceptions
2024-01-30 08:28:00,581:INFO:Importing libraries
2024-01-30 08:28:00,581:INFO:Copying training dataset
2024-01-30 08:28:00,618:INFO:Defining folds
2024-01-30 08:28:00,618:INFO:Declaring metric variables
2024-01-30 08:28:00,621:INFO:Importing untrained model
2024-01-30 08:28:00,624:INFO:Ridge Classifier Imported successfully
2024-01-30 08:28:00,630:INFO:Starting cross validation
2024-01-30 08:28:00,631:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:28:04,159:INFO:Calculating mean and std
2024-01-30 08:28:04,160:INFO:Creating metrics dataframe
2024-01-30 08:28:04,163:INFO:Uploading results into container
2024-01-30 08:28:04,164:INFO:Uploading model into container now
2024-01-30 08:28:04,164:INFO:_master_model_container: 4
2024-01-30 08:28:04,164:INFO:_display_container: 2
2024-01-30 08:28:04,164:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-01-30 08:28:04,164:INFO:create_model() successfully completed......................................
2024-01-30 08:28:04,241:INFO:SubProcess create_model() end ==================================
2024-01-30 08:28:04,241:INFO:Creating metrics dataframe
2024-01-30 08:28:04,249:INFO:Initializing Random Forest Classifier
2024-01-30 08:28:04,249:INFO:Total runtime is 0.7874972184499105 minutes
2024-01-30 08:28:04,251:INFO:SubProcess create_model() called ==================================
2024-01-30 08:28:04,252:INFO:Initializing create_model()
2024-01-30 08:28:04,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:28:04,252:INFO:Checking exceptions
2024-01-30 08:28:04,252:INFO:Importing libraries
2024-01-30 08:28:04,252:INFO:Copying training dataset
2024-01-30 08:28:04,297:INFO:Defining folds
2024-01-30 08:28:04,297:INFO:Declaring metric variables
2024-01-30 08:28:04,301:INFO:Importing untrained model
2024-01-30 08:28:04,320:INFO:Random Forest Classifier Imported successfully
2024-01-30 08:28:04,340:INFO:Starting cross validation
2024-01-30 08:28:04,341:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:28:29,999:INFO:Calculating mean and std
2024-01-30 08:28:30,000:INFO:Creating metrics dataframe
2024-01-30 08:28:30,003:INFO:Uploading results into container
2024-01-30 08:28:30,004:INFO:Uploading model into container now
2024-01-30 08:28:30,004:INFO:_master_model_container: 5
2024-01-30 08:28:30,004:INFO:_display_container: 2
2024-01-30 08:28:30,005:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2024-01-30 08:28:30,005:INFO:create_model() successfully completed......................................
2024-01-30 08:28:30,079:INFO:SubProcess create_model() end ==================================
2024-01-30 08:28:30,079:INFO:Creating metrics dataframe
2024-01-30 08:28:30,086:INFO:Initializing Linear Discriminant Analysis
2024-01-30 08:28:30,086:INFO:Total runtime is 1.2181208729743958 minutes
2024-01-30 08:28:30,089:INFO:SubProcess create_model() called ==================================
2024-01-30 08:28:30,089:INFO:Initializing create_model()
2024-01-30 08:28:30,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:28:30,089:INFO:Checking exceptions
2024-01-30 08:28:30,089:INFO:Importing libraries
2024-01-30 08:28:30,089:INFO:Copying training dataset
2024-01-30 08:28:30,119:INFO:Defining folds
2024-01-30 08:28:30,119:INFO:Declaring metric variables
2024-01-30 08:28:30,123:INFO:Importing untrained model
2024-01-30 08:28:30,127:INFO:Linear Discriminant Analysis Imported successfully
2024-01-30 08:28:30,133:INFO:Starting cross validation
2024-01-30 08:28:30,135:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:28:36,131:INFO:Calculating mean and std
2024-01-30 08:28:36,132:INFO:Creating metrics dataframe
2024-01-30 08:28:36,135:INFO:Uploading results into container
2024-01-30 08:28:36,135:INFO:Uploading model into container now
2024-01-30 08:28:36,136:INFO:_master_model_container: 6
2024-01-30 08:28:36,136:INFO:_display_container: 2
2024-01-30 08:28:36,136:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-30 08:28:36,136:INFO:create_model() successfully completed......................................
2024-01-30 08:28:36,211:INFO:SubProcess create_model() end ==================================
2024-01-30 08:28:36,212:INFO:Creating metrics dataframe
2024-01-30 08:28:36,222:INFO:Initializing Extra Trees Classifier
2024-01-30 08:28:36,222:INFO:Total runtime is 1.3203806479771931 minutes
2024-01-30 08:28:36,224:INFO:SubProcess create_model() called ==================================
2024-01-30 08:28:36,224:INFO:Initializing create_model()
2024-01-30 08:28:36,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:28:36,225:INFO:Checking exceptions
2024-01-30 08:28:36,225:INFO:Importing libraries
2024-01-30 08:28:36,225:INFO:Copying training dataset
2024-01-30 08:28:36,265:INFO:Defining folds
2024-01-30 08:28:36,265:INFO:Declaring metric variables
2024-01-30 08:28:36,269:INFO:Importing untrained model
2024-01-30 08:28:36,272:INFO:Extra Trees Classifier Imported successfully
2024-01-30 08:28:36,278:INFO:Starting cross validation
2024-01-30 08:28:36,279:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:29:08,508:INFO:Calculating mean and std
2024-01-30 08:29:08,509:INFO:Creating metrics dataframe
2024-01-30 08:29:08,514:INFO:Uploading results into container
2024-01-30 08:29:08,514:INFO:Uploading model into container now
2024-01-30 08:29:08,515:INFO:_master_model_container: 7
2024-01-30 08:29:08,515:INFO:_display_container: 2
2024-01-30 08:29:08,515:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2024-01-30 08:29:08,516:INFO:create_model() successfully completed......................................
2024-01-30 08:29:08,601:INFO:SubProcess create_model() end ==================================
2024-01-30 08:29:08,601:INFO:Creating metrics dataframe
2024-01-30 08:29:08,610:INFO:Initializing Light Gradient Boosting Machine
2024-01-30 08:29:08,610:INFO:Total runtime is 1.8601813077926637 minutes
2024-01-30 08:29:08,613:INFO:SubProcess create_model() called ==================================
2024-01-30 08:29:08,614:INFO:Initializing create_model()
2024-01-30 08:29:08,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f654ba1fa30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:29:08,614:INFO:Checking exceptions
2024-01-30 08:29:08,614:INFO:Importing libraries
2024-01-30 08:29:08,614:INFO:Copying training dataset
2024-01-30 08:29:08,652:INFO:Defining folds
2024-01-30 08:29:08,652:INFO:Declaring metric variables
2024-01-30 08:29:08,655:INFO:Importing untrained model
2024-01-30 08:29:08,660:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 08:29:08,666:INFO:Starting cross validation
2024-01-30 08:29:08,667:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:29:09,142:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:29:09,143:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:09,144:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 08:29:09,144:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 08:29:09,209:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:09,209:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:09,217:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:09,218:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:09,265:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.046471 secs. 1 sparse feature groups
2024-01-30 08:29:09,266:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:29:09,266:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:29:11,505:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:29:11,506:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:11,508:INFO:[LightGBM] [Info] Total Bins 158
2024-01-30 08:29:11,508:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 08:29:11,555:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:11,555:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:11,562:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:11,563:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:11,564:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001332 secs. 1 sparse feature groups
2024-01-30 08:29:11,565:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:29:11,565:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:29:13,291:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:29:13,291:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:13,293:INFO:[LightGBM] [Info] Total Bins 167
2024-01-30 08:29:13,293:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 08:29:13,342:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:13,342:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:13,348:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:13,351:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:13,354:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.002179 secs. 1 sparse feature groups
2024-01-30 08:29:13,355:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:29:13,355:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:29:15,279:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 08:29:15,280:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:15,281:INFO:[LightGBM] [Info] Total Bins 170
2024-01-30 08:29:15,281:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 08:29:15,343:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:15,343:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:15,354:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:15,355:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:15,358:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.002749 secs. 1 sparse feature groups
2024-01-30 08:29:15,359:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 08:29:15,359:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 08:29:18,306:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 08:29:18,307:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:18,310:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 08:29:18,310:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 41
2024-01-30 08:29:18,362:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:18,363:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:18,367:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:18,368:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:18,370:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001281 secs. 1 sparse feature groups
2024-01-30 08:29:18,370:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 08:29:18,370:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 08:29:19,314:INFO:Calculating mean and std
2024-01-30 08:29:19,315:INFO:Creating metrics dataframe
2024-01-30 08:29:19,317:INFO:Uploading results into container
2024-01-30 08:29:19,318:INFO:Uploading model into container now
2024-01-30 08:29:19,318:INFO:_master_model_container: 8
2024-01-30 08:29:19,319:INFO:_display_container: 2
2024-01-30 08:29:19,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:29:19,320:INFO:create_model() successfully completed......................................
2024-01-30 08:29:19,399:INFO:SubProcess create_model() end ==================================
2024-01-30 08:29:19,399:INFO:Creating metrics dataframe
2024-01-30 08:29:19,415:INFO:Initializing create_model()
2024-01-30 08:29:19,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:29:19,416:INFO:Checking exceptions
2024-01-30 08:29:19,417:INFO:Importing libraries
2024-01-30 08:29:19,417:INFO:Copying training dataset
2024-01-30 08:29:19,457:INFO:Defining folds
2024-01-30 08:29:19,458:INFO:Declaring metric variables
2024-01-30 08:29:19,458:INFO:Importing untrained model
2024-01-30 08:29:19,458:INFO:Declaring custom model
2024-01-30 08:29:19,458:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 08:29:19,459:INFO:Cross validation set to False
2024-01-30 08:29:19,459:INFO:Fitting Model
2024-01-30 08:29:20,050:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 08:29:20,050:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:20,053:INFO:[LightGBM] [Info] Total Bins 175
2024-01-30 08:29:20,053:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 42
2024-01-30 08:29:20,106:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:20,107:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:20,111:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:20,113:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:20,115:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.001756 secs. 1 sparse feature groups
2024-01-30 08:29:20,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 08:29:20,115:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 08:29:20,850:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:29:20,850:INFO:create_model() successfully completed......................................
2024-01-30 08:29:20,931:INFO:Creating Dashboard logs
2024-01-30 08:29:20,935:INFO:Model: Light Gradient Boosting Machine
2024-01-30 08:29:20,973:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 08:29:21,267:INFO:Initializing predict_model()
2024-01-30 08:29:21,268:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f64e436f490>)
2024-01-30 08:29:21,268:INFO:Checking exceptions
2024-01-30 08:29:21,268:INFO:Preloading libraries
2024-01-30 08:29:21,716:INFO:SubProcess plot_model() called ==================================
2024-01-30 08:29:21,717:INFO:Initializing plot_model()
2024-01-30 08:29:21,717:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpjt3nt8oa, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, system=False)
2024-01-30 08:29:21,717:INFO:Checking exceptions
2024-01-30 08:29:21,730:INFO:Preloading libraries
2024-01-30 08:29:21,733:INFO:Copying training dataset
2024-01-30 08:29:21,733:INFO:Plot type: auc
2024-01-30 08:29:21,942:INFO:Fitting Model
2024-01-30 08:29:21,947:INFO:Scoring test/hold-out set
2024-01-30 08:29:22,161:INFO:Saving '/tmp/tmpjt3nt8oa/AUC.png'
2024-01-30 08:29:22,356:INFO:Visual Rendered Successfully
2024-01-30 08:29:22,448:INFO:plot_model() successfully completed......................................
2024-01-30 08:29:22,449:INFO:Initializing plot_model()
2024-01-30 08:29:22,449:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpjt3nt8oa, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, system=False)
2024-01-30 08:29:22,449:INFO:Checking exceptions
2024-01-30 08:29:22,463:INFO:Preloading libraries
2024-01-30 08:29:22,466:INFO:Copying training dataset
2024-01-30 08:29:22,466:INFO:Plot type: confusion_matrix
2024-01-30 08:29:22,679:INFO:Fitting Model
2024-01-30 08:29:22,681:INFO:Scoring test/hold-out set
2024-01-30 08:29:22,828:INFO:Saving '/tmp/tmpjt3nt8oa/Confusion Matrix.png'
2024-01-30 08:29:22,917:INFO:Visual Rendered Successfully
2024-01-30 08:29:23,003:INFO:plot_model() successfully completed......................................
2024-01-30 08:29:23,004:INFO:Initializing plot_model()
2024-01-30 08:29:23,004:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpjt3nt8oa, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, system=False)
2024-01-30 08:29:23,004:INFO:Checking exceptions
2024-01-30 08:29:23,014:INFO:Preloading libraries
2024-01-30 08:29:23,047:INFO:Copying training dataset
2024-01-30 08:29:23,047:INFO:Plot type: feature
2024-01-30 08:29:23,055:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 08:29:23,134:INFO:Saving '/tmp/tmpjt3nt8oa/Feature Importance.png'
2024-01-30 08:29:23,282:INFO:Visual Rendered Successfully
2024-01-30 08:29:23,361:INFO:plot_model() successfully completed......................................
2024-01-30 08:29:23,362:INFO:SubProcess plot_model() end ==================================
2024-01-30 08:29:23,524:INFO:Creating Dashboard logs
2024-01-30 08:29:23,526:INFO:Model: Random Forest Classifier
2024-01-30 08:29:23,565:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 08:29:24,007:INFO:Creating Dashboard logs
2024-01-30 08:29:24,011:INFO:Model: Extra Trees Classifier
2024-01-30 08:29:24,048:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 08:29:24,486:INFO:Creating Dashboard logs
2024-01-30 08:29:24,489:INFO:Model: Decision Tree Classifier
2024-01-30 08:29:24,530:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2024-01-30 08:29:24,973:INFO:Creating Dashboard logs
2024-01-30 08:29:24,975:INFO:Model: Logistic Regression
2024-01-30 08:29:25,012:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-01-30 08:29:25,504:INFO:Creating Dashboard logs
2024-01-30 08:29:25,507:INFO:Model: Linear Discriminant Analysis
2024-01-30 08:29:25,546:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-01-30 08:29:25,974:INFO:Creating Dashboard logs
2024-01-30 08:29:25,977:INFO:Model: Ridge Classifier
2024-01-30 08:29:26,016:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2024-01-30 08:29:26,463:INFO:Creating Dashboard logs
2024-01-30 08:29:26,466:INFO:Model: Naive Bayes
2024-01-30 08:29:26,506:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-01-30 08:29:27,165:INFO:_master_model_container: 8
2024-01-30 08:29:27,165:INFO:_display_container: 2
2024-01-30 08:29:27,166:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:29:27,166:INFO:compare_models() successfully completed......................................
2024-01-30 08:29:27,185:INFO:Initializing create_model()
2024-01-30 08:29:27,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:29:27,186:INFO:Checking exceptions
2024-01-30 08:29:27,205:INFO:Importing libraries
2024-01-30 08:29:27,205:INFO:Copying training dataset
2024-01-30 08:29:27,259:INFO:Defining folds
2024-01-30 08:29:27,259:INFO:Declaring metric variables
2024-01-30 08:29:27,262:INFO:Importing untrained model
2024-01-30 08:29:27,266:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 08:29:27,274:INFO:Starting cross validation
2024-01-30 08:29:27,275:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:29:27,802:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:29:27,803:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:27,804:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 08:29:27,805:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 08:29:27,869:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:27,869:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:27,875:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:27,876:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:27,877:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001279 secs. 1 sparse feature groups
2024-01-30 08:29:27,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:29:27,878:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:29:29,266:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:29:29,266:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:29,269:INFO:[LightGBM] [Info] Total Bins 158
2024-01-30 08:29:29,269:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 41
2024-01-30 08:29:29,315:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:29,315:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:29,324:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:29,325:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:29,327:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001436 secs. 1 sparse feature groups
2024-01-30 08:29:29,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:29:29,327:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:29:30,521:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:29:30,521:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:30,525:INFO:[LightGBM] [Info] Total Bins 167
2024-01-30 08:29:30,525:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 08:29:30,572:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:30,572:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:30,576:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:30,578:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:30,580:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.002026 secs. 1 sparse feature groups
2024-01-30 08:29:30,581:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:29:30,581:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:29:31,806:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 08:29:31,813:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:31,814:INFO:[LightGBM] [Info] Total Bins 170
2024-01-30 08:29:31,815:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 42
2024-01-30 08:29:31,870:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:31,870:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:31,885:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:31,886:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:31,899:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.012207 secs. 1 sparse feature groups
2024-01-30 08:29:31,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 08:29:31,899:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 08:29:33,004:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 08:29:33,004:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:33,007:INFO:[LightGBM] [Info] Total Bins 159
2024-01-30 08:29:33,007:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 41
2024-01-30 08:29:33,062:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:33,062:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:33,066:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:33,068:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:33,069:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001427 secs. 1 sparse feature groups
2024-01-30 08:29:33,070:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 08:29:33,070:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 08:29:33,957:INFO:Calculating mean and std
2024-01-30 08:29:33,958:INFO:Creating metrics dataframe
2024-01-30 08:29:33,962:INFO:Finalizing model
2024-01-30 08:29:34,580:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 08:29:34,581:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:29:34,582:INFO:[LightGBM] [Info] Total Bins 175
2024-01-30 08:29:34,582:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 42
2024-01-30 08:29:34,629:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:29:34,629:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:29:34,633:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:29:34,635:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:29:34,638:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.002028 secs. 1 sparse feature groups
2024-01-30 08:29:34,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 08:29:34,639:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 08:29:35,276:INFO:Creating Dashboard logs
2024-01-30 08:29:35,279:INFO:Model: Light Gradient Boosting Machine
2024-01-30 08:29:35,321:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 08:29:35,597:INFO:Initializing predict_model()
2024-01-30 08:29:35,597:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f64e48b9360>)
2024-01-30 08:29:35,597:INFO:Checking exceptions
2024-01-30 08:29:35,597:INFO:Preloading libraries
2024-01-30 08:29:36,087:INFO:SubProcess plot_model() called ==================================
2024-01-30 08:29:36,087:INFO:Initializing plot_model()
2024-01-30 08:29:36,087:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpfp11496o, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, system=False)
2024-01-30 08:29:36,087:INFO:Checking exceptions
2024-01-30 08:29:36,100:INFO:Preloading libraries
2024-01-30 08:29:36,103:INFO:Copying training dataset
2024-01-30 08:29:36,103:INFO:Plot type: auc
2024-01-30 08:29:36,330:INFO:Fitting Model
2024-01-30 08:29:36,334:INFO:Scoring test/hold-out set
2024-01-30 08:29:36,508:INFO:Saving '/tmp/tmpfp11496o/AUC.png'
2024-01-30 08:29:36,671:INFO:Visual Rendered Successfully
2024-01-30 08:29:36,751:INFO:plot_model() successfully completed......................................
2024-01-30 08:29:36,753:INFO:Initializing plot_model()
2024-01-30 08:29:36,753:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpfp11496o, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, system=False)
2024-01-30 08:29:36,753:INFO:Checking exceptions
2024-01-30 08:29:36,766:INFO:Preloading libraries
2024-01-30 08:29:36,769:INFO:Copying training dataset
2024-01-30 08:29:36,769:INFO:Plot type: confusion_matrix
2024-01-30 08:29:36,987:INFO:Fitting Model
2024-01-30 08:29:36,990:INFO:Scoring test/hold-out set
2024-01-30 08:29:37,149:INFO:Saving '/tmp/tmpfp11496o/Confusion Matrix.png'
2024-01-30 08:29:37,234:INFO:Visual Rendered Successfully
2024-01-30 08:29:37,326:INFO:plot_model() successfully completed......................................
2024-01-30 08:29:37,327:INFO:Initializing plot_model()
2024-01-30 08:29:37,327:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpfp11496o, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, system=False)
2024-01-30 08:29:37,327:INFO:Checking exceptions
2024-01-30 08:29:37,348:INFO:Preloading libraries
2024-01-30 08:29:37,351:INFO:Copying training dataset
2024-01-30 08:29:37,351:INFO:Plot type: feature
2024-01-30 08:29:37,352:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 08:29:37,441:INFO:Saving '/tmp/tmpfp11496o/Feature Importance.png'
2024-01-30 08:29:37,600:INFO:Visual Rendered Successfully
2024-01-30 08:29:37,674:INFO:plot_model() successfully completed......................................
2024-01-30 08:29:37,675:INFO:SubProcess plot_model() end ==================================
2024-01-30 08:29:37,830:INFO:Uploading results into container
2024-01-30 08:29:37,831:INFO:Uploading model into container now
2024-01-30 08:29:37,839:INFO:_master_model_container: 9
2024-01-30 08:29:37,839:INFO:_display_container: 3
2024-01-30 08:29:37,840:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:29:37,840:INFO:create_model() successfully completed......................................
2024-01-30 08:29:37,935:INFO:Initializing plot_model()
2024-01-30 08:29:37,935:INFO:plot_model(plot=feature_all, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e657feb0>, system=True)
2024-01-30 08:29:37,935:INFO:Checking exceptions
2024-01-30 08:29:37,956:INFO:Preloading libraries
2024-01-30 08:29:37,958:INFO:Copying training dataset
2024-01-30 08:29:37,959:INFO:Plot type: feature_all
2024-01-30 08:29:38,029:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 08:29:38,464:INFO:Visual Rendered Successfully
2024-01-30 08:29:38,554:INFO:plot_model() successfully completed......................................
2024-01-30 08:29:38,585:INFO:PyCaret ClassificationExperiment
2024-01-30 08:29:38,585:INFO:Logging name: Baseline_model_exp_02
2024-01-30 08:29:38,585:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-30 08:29:38,586:INFO:version 3.2.0
2024-01-30 08:29:38,586:INFO:Initializing setup()
2024-01-30 08:29:38,586:INFO:self.USI: 8d8b
2024-01-30 08:29:38,586:INFO:self._variable_keys: {'pipeline', 'n_jobs_param', 'target_param', 'data', 'memory', 'gpu_n_jobs_param', 'y', 'X', 'y_train', 'X_test', 'y_test', 'fix_imbalance', 'USI', 'is_multiclass', 'seed', 'exp_id', 'exp_name_log', 'fold_shuffle_param', 'idx', 'html_param', 'gpu_param', 'logging_param', '_ml_usecase', 'fold_generator', 'fold_groups_param', 'log_plots_param', '_available_plots', 'X_train'}
2024-01-30 08:29:38,586:INFO:Checking environment
2024-01-30 08:29:38,586:INFO:python_version: 3.10.12
2024-01-30 08:29:38,586:INFO:python_build: ('main', 'Jul  5 2023 18:54:27')
2024-01-30 08:29:38,586:INFO:machine: x86_64
2024-01-30 08:29:38,586:INFO:platform: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 08:29:38,587:INFO:Memory: svmem(total=67274690560, available=58390495232, percent=13.2, used=6865833984, free=47254278144, active=10808639488, inactive=6229901312, buffers=4120576, cached=13150457856, shared=1178349568, slab=2221027328)
2024-01-30 08:29:38,588:INFO:Physical Core: 4
2024-01-30 08:29:38,588:INFO:Logical Core: 8
2024-01-30 08:29:38,588:INFO:Checking libraries
2024-01-30 08:29:38,588:INFO:System:
2024-01-30 08:29:38,588:INFO:    python: 3.10.12 (main, Jul  5 2023, 18:54:27) [GCC 11.2.0]
2024-01-30 08:29:38,588:INFO:executable: /home/zinger/miniconda3/bin/python
2024-01-30 08:29:38,588:INFO:   machine: Linux-6.5.0-15-generic-x86_64-with-glibc2.38
2024-01-30 08:29:38,588:INFO:PyCaret required dependencies:
2024-01-30 08:29:38,588:INFO:                 pip: 23.0.1
2024-01-30 08:29:38,588:INFO:          setuptools: 66.1.1
2024-01-30 08:29:38,588:INFO:             pycaret: 3.2.0
2024-01-30 08:29:38,588:INFO:             IPython: 8.12.2
2024-01-30 08:29:38,588:INFO:          ipywidgets: 8.1.1
2024-01-30 08:29:38,588:INFO:                tqdm: 4.65.0
2024-01-30 08:29:38,588:INFO:               numpy: 1.25.2
2024-01-30 08:29:38,588:INFO:              pandas: 1.5.3
2024-01-30 08:29:38,588:INFO:              jinja2: 3.1.2
2024-01-30 08:29:38,588:INFO:               scipy: 1.10.1
2024-01-30 08:29:38,588:INFO:              joblib: 1.3.1
2024-01-30 08:29:38,588:INFO:             sklearn: 1.2.2
2024-01-30 08:29:38,589:INFO:                pyod: 1.1.2
2024-01-30 08:29:38,589:INFO:            imblearn: 0.11.0
2024-01-30 08:29:38,589:INFO:   category_encoders: 2.6.3
2024-01-30 08:29:38,589:INFO:            lightgbm: 4.1.0
2024-01-30 08:29:38,589:INFO:               numba: 0.58.1
2024-01-30 08:29:38,589:INFO:            requests: 2.31.0
2024-01-30 08:29:38,589:INFO:          matplotlib: 3.6.0
2024-01-30 08:29:38,589:INFO:          scikitplot: 0.3.7
2024-01-30 08:29:38,589:INFO:         yellowbrick: 1.5
2024-01-30 08:29:38,589:INFO:              plotly: 5.9.0
2024-01-30 08:29:38,589:INFO:    plotly-resampler: Not installed
2024-01-30 08:29:38,589:INFO:             kaleido: 0.2.1
2024-01-30 08:29:38,589:INFO:           schemdraw: 0.15
2024-01-30 08:29:38,589:INFO:         statsmodels: 0.14.0
2024-01-30 08:29:38,589:INFO:              sktime: 0.21.1
2024-01-30 08:29:38,589:INFO:               tbats: 1.1.3
2024-01-30 08:29:38,589:INFO:            pmdarima: 2.0.4
2024-01-30 08:29:38,589:INFO:              psutil: 5.9.6
2024-01-30 08:29:38,589:INFO:          markupsafe: 2.1.1
2024-01-30 08:29:38,589:INFO:             pickle5: Not installed
2024-01-30 08:29:38,589:INFO:         cloudpickle: 2.2.1
2024-01-30 08:29:38,589:INFO:         deprecation: 2.1.0
2024-01-30 08:29:38,589:INFO:              xxhash: 3.4.1
2024-01-30 08:29:38,589:INFO:           wurlitzer: 3.0.3
2024-01-30 08:29:38,589:INFO:PyCaret optional dependencies:
2024-01-30 08:29:38,589:INFO:                shap: 0.44.0
2024-01-30 08:29:38,589:INFO:           interpret: Not installed
2024-01-30 08:29:38,590:INFO:                umap: Not installed
2024-01-30 08:29:38,590:INFO:     ydata_profiling: 4.6.2
2024-01-30 08:29:38,590:INFO:  explainerdashboard: Not installed
2024-01-30 08:29:38,590:INFO:             autoviz: Not installed
2024-01-30 08:29:38,590:INFO:           fairlearn: Not installed
2024-01-30 08:29:38,590:INFO:          deepchecks: Not installed
2024-01-30 08:29:38,590:INFO:             xgboost: Not installed
2024-01-30 08:29:38,590:INFO:            catboost: Not installed
2024-01-30 08:29:38,590:INFO:              kmodes: Not installed
2024-01-30 08:29:38,590:INFO:             mlxtend: Not installed
2024-01-30 08:29:38,590:INFO:       statsforecast: Not installed
2024-01-30 08:29:38,590:INFO:        tune_sklearn: Not installed
2024-01-30 08:29:38,590:INFO:                 ray: Not installed
2024-01-30 08:29:38,590:INFO:            hyperopt: Not installed
2024-01-30 08:29:38,590:INFO:              optuna: 3.5.0
2024-01-30 08:29:38,590:INFO:               skopt: 0.9.0
2024-01-30 08:29:38,590:INFO:              mlflow: 2.8.1
2024-01-30 08:29:38,590:INFO:              gradio: Not installed
2024-01-30 08:29:38,590:INFO:             fastapi: Not installed
2024-01-30 08:29:38,590:INFO:             uvicorn: Not installed
2024-01-30 08:29:38,590:INFO:              m2cgen: Not installed
2024-01-30 08:29:38,590:INFO:           evidently: Not installed
2024-01-30 08:29:38,590:INFO:               fugue: Not installed
2024-01-30 08:29:38,590:INFO:           streamlit: 1.28.2
2024-01-30 08:29:38,590:INFO:             prophet: Not installed
2024-01-30 08:29:38,590:INFO:None
2024-01-30 08:29:38,590:INFO:Set up GPU usage.
2024-01-30 08:29:38,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,591:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2024-01-30 08:29:38,591:INFO:Set up data.
2024-01-30 08:29:38,654:INFO:Set up folding strategy.
2024-01-30 08:29:38,654:INFO:Set up train/test split.
2024-01-30 08:29:38,712:INFO:Set up index.
2024-01-30 08:29:38,714:INFO:Assigning column types.
2024-01-30 08:29:38,723:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-30 08:29:38,723:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,757:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 08:29:38,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,757:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,758:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:29:38,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,775:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:38,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:38,866:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,904:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-30 08:29:38,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,905:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:29:38,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,925:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:38,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,007:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-30 08:29:39,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,042:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:29:39,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,065:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,185:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-30 08:29:39,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,297:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-30 08:29:39,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,504:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,507:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:39,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:39,592:INFO:Preparing preprocessing pipeline...
2024-01-30 08:29:39,595:INFO:Set up simple imputation.
2024-01-30 08:29:39,607:INFO:Set up encoding of categorical features.
2024-01-30 08:29:39,837:INFO:Finished creating preprocessing pipeline.
2024-01-30 08:29:39,842:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 08:29:39,842:INFO:Creating final display dataframe.
2024-01-30 08:29:40,511:INFO:Setup _display_container:                     Description                  Value
0                    Session id                     42
1                        Target      app_complete_flag
2                   Target type                 Binary
3           Original data shape            (238964, 7)
4        Transformed data shape           (238964, 39)
5   Transformed train set shape           (167274, 39)
6    Transformed test set shape            (71690, 39)
7              Numeric features                      3
8          Categorical features                      3
9                    Preprocess                   True
10              Imputation type                 simple
11           Numeric imputation                   mean
12       Categorical imputation                   mode
13     Maximum one-hot encoding                     25
14              Encoding method                   None
15               Fold Generator        StratifiedKFold
16                  Fold Number                     10
17                     CPU Jobs                     -1
18                      Use GPU                   True
19               Log Experiment           MlflowLogger
20              Experiment Name  Baseline_model_exp_02
21                          USI                   8d8b
2024-01-30 08:29:40,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,556:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:40,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:40,656:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-30 08:29:40,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:40,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-30 08:29:40,802:INFO:Logging experiment in loggers
2024-01-30 08:29:41,036:INFO:SubProcess save_model() called ==================================
2024-01-30 08:29:41,044:INFO:Initializing save_model()
2024-01-30 08:29:41,044:INFO:save_model(model=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=/tmp/tmpy3uh46su/Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-01-30 08:29:41,044:INFO:Adding model into prep_pipe
2024-01-30 08:29:41,044:WARNING:Only Model saved as it was a pipeline.
2024-01-30 08:29:41,048:INFO:/tmp/tmpy3uh46su/Transformation Pipeline.pkl saved in current working directory
2024-01-30 08:29:41,052:INFO:Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['first_platform_c',
                                             'first_utm_medium_c',
                                             'first_utm_source_c'],
                                    transformer=OneHotEncoder(cols=['first_platform_c',
                                                                    'first_utm_medium_c',
                                                                    'first_utm_source_c'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-01-30 08:29:41,052:INFO:save_model() successfully completed......................................
2024-01-30 08:29:41,137:INFO:SubProcess save_model() end ==================================
2024-01-30 08:29:41,611:INFO:setup() successfully completed in 2.22s...............
2024-01-30 08:29:41,628:INFO:Initializing compare_models()
2024-01-30 08:29:41,628:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, include=None, fold=5, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, 'include': None, 'exclude': ['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'])
2024-01-30 08:29:41,629:INFO:Checking exceptions
2024-01-30 08:29:41,651:INFO:Preparing display monitor
2024-01-30 08:29:41,678:INFO:Initializing Logistic Regression
2024-01-30 08:29:41,678:INFO:Total runtime is 3.9656956990559895e-06 minutes
2024-01-30 08:29:41,681:INFO:SubProcess create_model() called ==================================
2024-01-30 08:29:41,682:INFO:Initializing create_model()
2024-01-30 08:29:41,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:29:41,682:INFO:Checking exceptions
2024-01-30 08:29:41,682:INFO:Importing libraries
2024-01-30 08:29:41,682:INFO:Copying training dataset
2024-01-30 08:29:41,743:INFO:Defining folds
2024-01-30 08:29:41,743:INFO:Declaring metric variables
2024-01-30 08:29:41,748:INFO:Importing untrained model
2024-01-30 08:29:41,752:INFO:Logistic Regression Imported successfully
2024-01-30 08:29:41,758:INFO:Starting cross validation
2024-01-30 08:29:41,760:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:30:01,227:INFO:Calculating mean and std
2024-01-30 08:30:01,228:INFO:Creating metrics dataframe
2024-01-30 08:30:01,231:INFO:Uploading results into container
2024-01-30 08:30:01,232:INFO:Uploading model into container now
2024-01-30 08:30:01,232:INFO:_master_model_container: 1
2024-01-30 08:30:01,232:INFO:_display_container: 2
2024-01-30 08:30:01,233:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-30 08:30:01,233:INFO:create_model() successfully completed......................................
2024-01-30 08:30:01,314:INFO:SubProcess create_model() end ==================================
2024-01-30 08:30:01,314:INFO:Creating metrics dataframe
2024-01-30 08:30:01,327:INFO:Initializing Naive Bayes
2024-01-30 08:30:01,327:INFO:Total runtime is 0.32748608191808065 minutes
2024-01-30 08:30:01,332:INFO:SubProcess create_model() called ==================================
2024-01-30 08:30:01,332:INFO:Initializing create_model()
2024-01-30 08:30:01,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:30:01,332:INFO:Checking exceptions
2024-01-30 08:30:01,332:INFO:Importing libraries
2024-01-30 08:30:01,332:INFO:Copying training dataset
2024-01-30 08:30:01,362:INFO:Defining folds
2024-01-30 08:30:01,362:INFO:Declaring metric variables
2024-01-30 08:30:01,365:INFO:Importing untrained model
2024-01-30 08:30:01,368:INFO:Naive Bayes Imported successfully
2024-01-30 08:30:01,375:INFO:Starting cross validation
2024-01-30 08:30:01,377:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:30:04,526:INFO:Calculating mean and std
2024-01-30 08:30:04,527:INFO:Creating metrics dataframe
2024-01-30 08:30:04,529:INFO:Uploading results into container
2024-01-30 08:30:04,530:INFO:Uploading model into container now
2024-01-30 08:30:04,530:INFO:_master_model_container: 2
2024-01-30 08:30:04,530:INFO:_display_container: 2
2024-01-30 08:30:04,530:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-30 08:30:04,530:INFO:create_model() successfully completed......................................
2024-01-30 08:30:04,611:INFO:SubProcess create_model() end ==================================
2024-01-30 08:30:04,611:INFO:Creating metrics dataframe
2024-01-30 08:30:04,619:INFO:Initializing Decision Tree Classifier
2024-01-30 08:30:04,620:INFO:Total runtime is 0.38236021995544434 minutes
2024-01-30 08:30:04,635:INFO:SubProcess create_model() called ==================================
2024-01-30 08:30:04,636:INFO:Initializing create_model()
2024-01-30 08:30:04,637:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:30:04,645:INFO:Checking exceptions
2024-01-30 08:30:04,645:INFO:Importing libraries
2024-01-30 08:30:04,645:INFO:Copying training dataset
2024-01-30 08:30:04,686:INFO:Defining folds
2024-01-30 08:30:04,687:INFO:Declaring metric variables
2024-01-30 08:30:04,690:INFO:Importing untrained model
2024-01-30 08:30:04,694:INFO:Decision Tree Classifier Imported successfully
2024-01-30 08:30:04,700:INFO:Starting cross validation
2024-01-30 08:30:04,702:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:30:08,825:INFO:Calculating mean and std
2024-01-30 08:30:08,826:INFO:Creating metrics dataframe
2024-01-30 08:30:08,829:INFO:Uploading results into container
2024-01-30 08:30:08,830:INFO:Uploading model into container now
2024-01-30 08:30:08,830:INFO:_master_model_container: 3
2024-01-30 08:30:08,830:INFO:_display_container: 2
2024-01-30 08:30:08,830:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=42, splitter='best')
2024-01-30 08:30:08,830:INFO:create_model() successfully completed......................................
2024-01-30 08:30:08,912:INFO:SubProcess create_model() end ==================================
2024-01-30 08:30:08,912:INFO:Creating metrics dataframe
2024-01-30 08:30:08,920:INFO:Initializing Ridge Classifier
2024-01-30 08:30:08,920:INFO:Total runtime is 0.4540353814760844 minutes
2024-01-30 08:30:08,923:INFO:SubProcess create_model() called ==================================
2024-01-30 08:30:08,923:INFO:Initializing create_model()
2024-01-30 08:30:08,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:30:08,924:INFO:Checking exceptions
2024-01-30 08:30:08,924:INFO:Importing libraries
2024-01-30 08:30:08,924:INFO:Copying training dataset
2024-01-30 08:30:08,953:INFO:Defining folds
2024-01-30 08:30:08,953:INFO:Declaring metric variables
2024-01-30 08:30:08,956:INFO:Importing untrained model
2024-01-30 08:30:08,959:INFO:Ridge Classifier Imported successfully
2024-01-30 08:30:08,965:INFO:Starting cross validation
2024-01-30 08:30:08,966:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:30:12,377:INFO:Calculating mean and std
2024-01-30 08:30:12,378:INFO:Creating metrics dataframe
2024-01-30 08:30:12,381:INFO:Uploading results into container
2024-01-30 08:30:12,381:INFO:Uploading model into container now
2024-01-30 08:30:12,381:INFO:_master_model_container: 4
2024-01-30 08:30:12,382:INFO:_display_container: 2
2024-01-30 08:30:12,382:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=42, solver='auto',
                tol=0.0001)
2024-01-30 08:30:12,382:INFO:create_model() successfully completed......................................
2024-01-30 08:30:12,463:INFO:SubProcess create_model() end ==================================
2024-01-30 08:30:12,463:INFO:Creating metrics dataframe
2024-01-30 08:30:12,472:INFO:Initializing Random Forest Classifier
2024-01-30 08:30:12,472:INFO:Total runtime is 0.513231364885966 minutes
2024-01-30 08:30:12,475:INFO:SubProcess create_model() called ==================================
2024-01-30 08:30:12,475:INFO:Initializing create_model()
2024-01-30 08:30:12,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:30:12,475:INFO:Checking exceptions
2024-01-30 08:30:12,475:INFO:Importing libraries
2024-01-30 08:30:12,475:INFO:Copying training dataset
2024-01-30 08:30:12,513:INFO:Defining folds
2024-01-30 08:30:12,513:INFO:Declaring metric variables
2024-01-30 08:30:12,516:INFO:Importing untrained model
2024-01-30 08:30:12,521:INFO:Random Forest Classifier Imported successfully
2024-01-30 08:30:12,531:INFO:Starting cross validation
2024-01-30 08:30:12,533:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:30:38,551:INFO:Calculating mean and std
2024-01-30 08:30:38,552:INFO:Creating metrics dataframe
2024-01-30 08:30:38,556:INFO:Uploading results into container
2024-01-30 08:30:38,557:INFO:Uploading model into container now
2024-01-30 08:30:38,558:INFO:_master_model_container: 5
2024-01-30 08:30:38,558:INFO:_display_container: 2
2024-01-30 08:30:38,558:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=42, verbose=0, warm_start=False)
2024-01-30 08:30:38,558:INFO:create_model() successfully completed......................................
2024-01-30 08:30:38,642:INFO:SubProcess create_model() end ==================================
2024-01-30 08:30:38,642:INFO:Creating metrics dataframe
2024-01-30 08:30:38,651:INFO:Initializing Linear Discriminant Analysis
2024-01-30 08:30:38,651:INFO:Total runtime is 0.9495400190353394 minutes
2024-01-30 08:30:38,653:INFO:SubProcess create_model() called ==================================
2024-01-30 08:30:38,653:INFO:Initializing create_model()
2024-01-30 08:30:38,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:30:38,653:INFO:Checking exceptions
2024-01-30 08:30:38,653:INFO:Importing libraries
2024-01-30 08:30:38,654:INFO:Copying training dataset
2024-01-30 08:30:38,683:INFO:Defining folds
2024-01-30 08:30:38,683:INFO:Declaring metric variables
2024-01-30 08:30:38,685:INFO:Importing untrained model
2024-01-30 08:30:38,689:INFO:Linear Discriminant Analysis Imported successfully
2024-01-30 08:30:38,695:INFO:Starting cross validation
2024-01-30 08:30:38,696:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:30:44,356:INFO:Calculating mean and std
2024-01-30 08:30:44,357:INFO:Creating metrics dataframe
2024-01-30 08:30:44,362:INFO:Uploading results into container
2024-01-30 08:30:44,362:INFO:Uploading model into container now
2024-01-30 08:30:44,363:INFO:_master_model_container: 6
2024-01-30 08:30:44,363:INFO:_display_container: 2
2024-01-30 08:30:44,363:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-30 08:30:44,364:INFO:create_model() successfully completed......................................
2024-01-30 08:30:44,459:INFO:SubProcess create_model() end ==================================
2024-01-30 08:30:44,459:INFO:Creating metrics dataframe
2024-01-30 08:30:44,469:INFO:Initializing Extra Trees Classifier
2024-01-30 08:30:44,469:INFO:Total runtime is 1.0465092301368712 minutes
2024-01-30 08:30:44,474:INFO:SubProcess create_model() called ==================================
2024-01-30 08:30:44,474:INFO:Initializing create_model()
2024-01-30 08:30:44,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:30:44,474:INFO:Checking exceptions
2024-01-30 08:30:44,474:INFO:Importing libraries
2024-01-30 08:30:44,474:INFO:Copying training dataset
2024-01-30 08:30:44,511:INFO:Defining folds
2024-01-30 08:30:44,511:INFO:Declaring metric variables
2024-01-30 08:30:44,515:INFO:Importing untrained model
2024-01-30 08:30:44,518:INFO:Extra Trees Classifier Imported successfully
2024-01-30 08:30:44,526:INFO:Starting cross validation
2024-01-30 08:30:44,527:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:31:12,356:INFO:Calculating mean and std
2024-01-30 08:31:12,357:INFO:Creating metrics dataframe
2024-01-30 08:31:12,360:INFO:Uploading results into container
2024-01-30 08:31:12,361:INFO:Uploading model into container now
2024-01-30 08:31:12,361:INFO:_master_model_container: 7
2024-01-30 08:31:12,361:INFO:_display_container: 2
2024-01-30 08:31:12,361:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=42, verbose=0, warm_start=False)
2024-01-30 08:31:12,361:INFO:create_model() successfully completed......................................
2024-01-30 08:31:12,446:INFO:SubProcess create_model() end ==================================
2024-01-30 08:31:12,447:INFO:Creating metrics dataframe
2024-01-30 08:31:12,456:INFO:Initializing Light Gradient Boosting Machine
2024-01-30 08:31:12,456:INFO:Total runtime is 1.5129607597986856 minutes
2024-01-30 08:31:12,458:INFO:SubProcess create_model() called ==================================
2024-01-30 08:31:12,459:INFO:Initializing create_model()
2024-01-30 08:31:12,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e4634730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:31:12,459:INFO:Checking exceptions
2024-01-30 08:31:12,459:INFO:Importing libraries
2024-01-30 08:31:12,459:INFO:Copying training dataset
2024-01-30 08:31:12,498:INFO:Defining folds
2024-01-30 08:31:12,498:INFO:Declaring metric variables
2024-01-30 08:31:12,501:INFO:Importing untrained model
2024-01-30 08:31:12,504:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 08:31:12,511:INFO:Starting cross validation
2024-01-30 08:31:12,513:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:31:13,046:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:31:13,047:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:13,047:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 08:31:13,048:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:13,121:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:13,121:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:13,125:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:13,127:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:13,128:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001428 secs. 1 sparse feature groups
2024-01-30 08:31:13,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:31:13,132:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:31:14,606:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:31:14,606:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:14,607:INFO:[LightGBM] [Info] Total Bins 114
2024-01-30 08:31:14,607:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:14,655:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:14,655:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:14,660:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:14,661:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:14,663:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups
2024-01-30 08:31:14,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:31:14,663:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:31:15,949:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:31:15,956:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:15,957:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:31:15,957:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:16,006:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:16,006:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:16,011:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:16,012:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:16,014:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups
2024-01-30 08:31:16,014:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:31:16,014:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:31:17,316:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 08:31:17,317:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:17,317:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:31:17,317:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:17,366:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:17,366:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:17,371:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:17,373:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:17,374:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001247 secs. 1 sparse feature groups
2024-01-30 08:31:17,374:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 08:31:17,375:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 08:31:18,659:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 08:31:18,659:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:18,660:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:31:18,660:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 38
2024-01-30 08:31:18,710:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:18,710:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:18,714:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:18,716:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:18,717:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups
2024-01-30 08:31:18,718:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 08:31:18,718:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 08:31:19,412:INFO:Calculating mean and std
2024-01-30 08:31:19,413:INFO:Creating metrics dataframe
2024-01-30 08:31:19,415:INFO:Uploading results into container
2024-01-30 08:31:19,416:INFO:Uploading model into container now
2024-01-30 08:31:19,416:INFO:_master_model_container: 8
2024-01-30 08:31:19,416:INFO:_display_container: 2
2024-01-30 08:31:19,417:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:31:19,417:INFO:create_model() successfully completed......................................
2024-01-30 08:31:19,498:INFO:SubProcess create_model() end ==================================
2024-01-30 08:31:19,498:INFO:Creating metrics dataframe
2024-01-30 08:31:19,515:INFO:Initializing create_model()
2024-01-30 08:31:19,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:31:19,516:INFO:Checking exceptions
2024-01-30 08:31:19,517:INFO:Importing libraries
2024-01-30 08:31:19,517:INFO:Copying training dataset
2024-01-30 08:31:19,557:INFO:Defining folds
2024-01-30 08:31:19,558:INFO:Declaring metric variables
2024-01-30 08:31:19,558:INFO:Importing untrained model
2024-01-30 08:31:19,558:INFO:Declaring custom model
2024-01-30 08:31:19,559:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 08:31:19,560:INFO:Cross validation set to False
2024-01-30 08:31:19,560:INFO:Fitting Model
2024-01-30 08:31:20,162:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 08:31:20,179:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:20,194:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 08:31:20,195:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 38
2024-01-30 08:31:20,246:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:20,246:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:20,251:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:20,253:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:20,255:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.002068 secs. 1 sparse feature groups
2024-01-30 08:31:20,256:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 08:31:20,256:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 08:31:20,843:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:31:20,843:INFO:create_model() successfully completed......................................
2024-01-30 08:31:20,928:INFO:Creating Dashboard logs
2024-01-30 08:31:20,933:INFO:Model: Light Gradient Boosting Machine
2024-01-30 08:31:20,974:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 08:31:21,241:INFO:Initializing predict_model()
2024-01-30 08:31:21,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f64e48b3640>)
2024-01-30 08:31:21,241:INFO:Checking exceptions
2024-01-30 08:31:21,241:INFO:Preloading libraries
2024-01-30 08:31:21,683:INFO:SubProcess plot_model() called ==================================
2024-01-30 08:31:21,683:INFO:Initializing plot_model()
2024-01-30 08:31:21,683:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp6s0p7zx9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 08:31:21,684:INFO:Checking exceptions
2024-01-30 08:31:21,696:INFO:Preloading libraries
2024-01-30 08:31:21,699:INFO:Copying training dataset
2024-01-30 08:31:21,699:INFO:Plot type: auc
2024-01-30 08:31:21,902:INFO:Fitting Model
2024-01-30 08:31:21,907:INFO:Scoring test/hold-out set
2024-01-30 08:31:22,126:INFO:Saving '/tmp/tmp6s0p7zx9/AUC.png'
2024-01-30 08:31:22,326:INFO:Visual Rendered Successfully
2024-01-30 08:31:22,415:INFO:plot_model() successfully completed......................................
2024-01-30 08:31:22,416:INFO:Initializing plot_model()
2024-01-30 08:31:22,416:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp6s0p7zx9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 08:31:22,417:INFO:Checking exceptions
2024-01-30 08:31:22,431:INFO:Preloading libraries
2024-01-30 08:31:22,434:INFO:Copying training dataset
2024-01-30 08:31:22,434:INFO:Plot type: confusion_matrix
2024-01-30 08:31:22,630:INFO:Fitting Model
2024-01-30 08:31:22,633:INFO:Scoring test/hold-out set
2024-01-30 08:31:22,775:INFO:Saving '/tmp/tmp6s0p7zx9/Confusion Matrix.png'
2024-01-30 08:31:22,862:INFO:Visual Rendered Successfully
2024-01-30 08:31:22,948:INFO:plot_model() successfully completed......................................
2024-01-30 08:31:22,949:INFO:Initializing plot_model()
2024-01-30 08:31:22,949:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmp6s0p7zx9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 08:31:22,949:INFO:Checking exceptions
2024-01-30 08:31:22,960:INFO:Preloading libraries
2024-01-30 08:31:22,963:INFO:Copying training dataset
2024-01-30 08:31:22,963:INFO:Plot type: feature
2024-01-30 08:31:22,973:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 08:31:23,055:INFO:Saving '/tmp/tmp6s0p7zx9/Feature Importance.png'
2024-01-30 08:31:23,186:INFO:Visual Rendered Successfully
2024-01-30 08:31:23,267:INFO:plot_model() successfully completed......................................
2024-01-30 08:31:23,268:INFO:SubProcess plot_model() end ==================================
2024-01-30 08:31:23,431:INFO:Creating Dashboard logs
2024-01-30 08:31:23,434:INFO:Model: Random Forest Classifier
2024-01-30 08:31:23,473:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 08:31:23,996:INFO:Creating Dashboard logs
2024-01-30 08:31:23,999:INFO:Model: Extra Trees Classifier
2024-01-30 08:31:24,039:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}
2024-01-30 08:31:24,496:INFO:Creating Dashboard logs
2024-01-30 08:31:24,500:INFO:Model: Decision Tree Classifier
2024-01-30 08:31:24,536:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}
2024-01-30 08:31:24,995:INFO:Creating Dashboard logs
2024-01-30 08:31:24,997:INFO:Model: Logistic Regression
2024-01-30 08:31:25,035:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2024-01-30 08:31:25,498:INFO:Creating Dashboard logs
2024-01-30 08:31:25,501:INFO:Model: Ridge Classifier
2024-01-30 08:31:25,542:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}
2024-01-30 08:31:25,969:INFO:Creating Dashboard logs
2024-01-30 08:31:25,972:INFO:Model: Linear Discriminant Analysis
2024-01-30 08:31:26,013:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2024-01-30 08:31:26,487:INFO:Creating Dashboard logs
2024-01-30 08:31:26,491:INFO:Model: Naive Bayes
2024-01-30 08:31:26,530:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2024-01-30 08:31:26,985:INFO:_master_model_container: 8
2024-01-30 08:31:26,985:INFO:_display_container: 2
2024-01-30 08:31:26,985:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:31:26,986:INFO:compare_models() successfully completed......................................
2024-01-30 08:31:27,022:INFO:Initializing create_model()
2024-01-30 08:31:27,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 08:31:27,022:INFO:Checking exceptions
2024-01-30 08:31:27,057:INFO:Importing libraries
2024-01-30 08:31:27,057:INFO:Copying training dataset
2024-01-30 08:31:27,132:INFO:Defining folds
2024-01-30 08:31:27,132:INFO:Declaring metric variables
2024-01-30 08:31:27,136:INFO:Importing untrained model
2024-01-30 08:31:27,139:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 08:31:27,148:INFO:Starting cross validation
2024-01-30 08:31:27,150:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2024-01-30 08:31:27,687:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:31:27,687:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:27,689:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 08:31:27,690:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:27,746:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:27,746:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:27,750:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:27,751:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:27,756:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.004593 secs. 1 sparse feature groups
2024-01-30 08:31:27,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:31:27,758:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:31:29,109:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:31:29,110:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:29,111:INFO:[LightGBM] [Info] Total Bins 114
2024-01-30 08:31:29,111:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:29,160:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:29,160:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:29,166:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:29,167:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:29,168:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups
2024-01-30 08:31:29,169:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:31:29,169:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:31:30,385:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66634
2024-01-30 08:31:30,386:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:30,387:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:31:30,387:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:30,433:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:30,433:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:30,440:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:30,441:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:30,443:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001485 secs. 1 sparse feature groups
2024-01-30 08:31:30,443:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008235
2024-01-30 08:31:30,444:INFO:[LightGBM] [Info] Start training from score 0.008235
2024-01-30 08:31:31,682:INFO:[LightGBM] [Info] Number of positive: 67184, number of negative: 66635
2024-01-30 08:31:31,682:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:31,683:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:31:31,683:INFO:[LightGBM] [Info] Number of data points in the train set: 133819, number of used features: 38
2024-01-30 08:31:31,735:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:31,735:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:31,740:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:31,742:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:31,743:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001478 secs. 1 sparse feature groups
2024-01-30 08:31:31,744:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502051 -> initscore=0.008205
2024-01-30 08:31:31,744:INFO:[LightGBM] [Info] Start training from score 0.008205
2024-01-30 08:31:33,076:INFO:[LightGBM] [Info] Number of positive: 67185, number of negative: 66635
2024-01-30 08:31:33,077:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:33,077:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 08:31:33,078:INFO:[LightGBM] [Info] Number of data points in the train set: 133820, number of used features: 38
2024-01-30 08:31:33,123:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:33,123:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:33,128:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:33,130:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:33,131:INFO:[LightGBM] [Info] 5 dense feature groups (1.02 MB) transferred to GPU in 0.001346 secs. 1 sparse feature groups
2024-01-30 08:31:33,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502055 -> initscore=0.008220
2024-01-30 08:31:33,132:INFO:[LightGBM] [Info] Start training from score 0.008220
2024-01-30 08:31:33,981:INFO:Calculating mean and std
2024-01-30 08:31:33,982:INFO:Creating metrics dataframe
2024-01-30 08:31:33,990:INFO:Finalizing model
2024-01-30 08:31:34,587:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 08:31:34,588:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 08:31:34,589:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 08:31:34,589:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 38
2024-01-30 08:31:34,637:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 08:31:34,637:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 08:31:34,643:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 08:31:34,645:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 08:31:34,647:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.001672 secs. 1 sparse feature groups
2024-01-30 08:31:34,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 08:31:34,649:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 08:31:35,415:INFO:Creating Dashboard logs
2024-01-30 08:31:35,418:INFO:Model: Light Gradient Boosting Machine
2024-01-30 08:31:35,497:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu'}
2024-01-30 08:31:35,771:INFO:Initializing predict_model()
2024-01-30 08:31:35,771:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f64df7ed120>)
2024-01-30 08:31:35,771:INFO:Checking exceptions
2024-01-30 08:31:35,771:INFO:Preloading libraries
2024-01-30 08:31:36,216:INFO:SubProcess plot_model() called ==================================
2024-01-30 08:31:36,217:INFO:Initializing plot_model()
2024-01-30 08:31:36,217:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmppghk94p9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 08:31:36,217:INFO:Checking exceptions
2024-01-30 08:31:36,229:INFO:Preloading libraries
2024-01-30 08:31:36,232:INFO:Copying training dataset
2024-01-30 08:31:36,233:INFO:Plot type: auc
2024-01-30 08:31:36,457:INFO:Fitting Model
2024-01-30 08:31:36,460:INFO:Scoring test/hold-out set
2024-01-30 08:31:36,696:INFO:Saving '/tmp/tmppghk94p9/AUC.png'
2024-01-30 08:31:36,873:INFO:Visual Rendered Successfully
2024-01-30 08:31:36,962:INFO:plot_model() successfully completed......................................
2024-01-30 08:31:36,963:INFO:Initializing plot_model()
2024-01-30 08:31:36,963:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmppghk94p9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 08:31:36,963:INFO:Checking exceptions
2024-01-30 08:31:36,973:INFO:Preloading libraries
2024-01-30 08:31:36,976:INFO:Copying training dataset
2024-01-30 08:31:36,976:INFO:Plot type: confusion_matrix
2024-01-30 08:31:37,185:INFO:Fitting Model
2024-01-30 08:31:37,188:INFO:Scoring test/hold-out set
2024-01-30 08:31:37,332:INFO:Saving '/tmp/tmppghk94p9/Confusion Matrix.png'
2024-01-30 08:31:37,421:INFO:Visual Rendered Successfully
2024-01-30 08:31:37,518:INFO:plot_model() successfully completed......................................
2024-01-30 08:31:37,519:INFO:Initializing plot_model()
2024-01-30 08:31:37,519:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmppghk94p9, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 08:31:37,520:INFO:Checking exceptions
2024-01-30 08:31:37,532:INFO:Preloading libraries
2024-01-30 08:31:37,536:INFO:Copying training dataset
2024-01-30 08:31:37,536:INFO:Plot type: feature
2024-01-30 08:31:37,547:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 08:31:37,654:INFO:Saving '/tmp/tmppghk94p9/Feature Importance.png'
2024-01-30 08:31:37,822:INFO:Visual Rendered Successfully
2024-01-30 08:31:37,923:INFO:plot_model() successfully completed......................................
2024-01-30 08:31:37,924:INFO:SubProcess plot_model() end ==================================
2024-01-30 08:31:38,105:INFO:Uploading results into container
2024-01-30 08:31:38,106:INFO:Uploading model into container now
2024-01-30 08:31:38,117:INFO:_master_model_container: 9
2024-01-30 08:31:38,117:INFO:_display_container: 3
2024-01-30 08:31:38,118:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 08:31:38,118:INFO:create_model() successfully completed......................................
2024-01-30 08:32:07,865:INFO:Initializing tune_model()
2024-01-30 08:32:07,865:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=10, round=4, n_iter=100, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=True, verbose=True, tuner_verbose=True, return_train_score=True, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>)
2024-01-30 08:32:07,865:INFO:Checking exceptions
2024-01-30 08:32:07,866:INFO:Soft dependency imported: optuna: 3.5.0
2024-01-30 08:32:08,052:INFO:Copying training dataset
2024-01-30 08:32:08,081:INFO:Checking base model
2024-01-30 08:32:08,081:INFO:Base model : Light Gradient Boosting Machine
2024-01-30 08:32:08,085:INFO:Declaring metric variables
2024-01-30 08:32:08,088:INFO:Defining Hyperparameters
2024-01-30 08:32:08,182:INFO:Tuning with n_jobs=1
2024-01-30 08:32:08,183:INFO:Initializing optuna.integration.OptunaSearchCV
2024-01-30 09:48:37,642:INFO:best_params: {'actual_estimator__num_leaves': 135, 'actual_estimator__learning_rate': 0.02763687273676973, 'actual_estimator__n_estimators': 217, 'actual_estimator__min_split_gain': 0.13835866595104254, 'actual_estimator__reg_alpha': 1.4291476325379542e-10, 'actual_estimator__reg_lambda': 1.3732436522309388e-05, 'actual_estimator__feature_fraction': 0.7953631875848566, 'actual_estimator__bagging_fraction': 0.8026208127603797, 'actual_estimator__bagging_freq': 1, 'actual_estimator__min_child_samples': 9}
2024-01-30 09:48:37,652:INFO:Hyperparameter search completed
2024-01-30 09:48:37,652:INFO:SubProcess create_model() called ==================================
2024-01-30 09:48:37,652:INFO:Initializing create_model()
2024-01-30 09:48:37,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f64e6b6c0a0>, model_only=True, return_train_score=True, error_score=0.0, kwargs={'num_leaves': 135, 'learning_rate': 0.02763687273676973, 'n_estimators': 217, 'min_split_gain': 0.13835866595104254, 'reg_alpha': 1.4291476325379542e-10, 'reg_lambda': 1.3732436522309388e-05, 'feature_fraction': 0.7953631875848566, 'bagging_fraction': 0.8026208127603797, 'bagging_freq': 1, 'min_child_samples': 9})
2024-01-30 09:48:37,652:INFO:Checking exceptions
2024-01-30 09:48:37,652:INFO:Importing libraries
2024-01-30 09:48:37,652:INFO:Copying training dataset
2024-01-30 09:48:37,707:INFO:Defining folds
2024-01-30 09:48:37,707:INFO:Declaring metric variables
2024-01-30 09:48:37,712:INFO:Importing untrained model
2024-01-30 09:48:37,712:INFO:Declaring custom model
2024-01-30 09:48:37,715:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 09:48:37,721:INFO:Starting cross validation
2024-01-30 09:48:37,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-01-30 09:48:38,241:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:38,241:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:38,241:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:38,289:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:38,289:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:38,289:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:38,290:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74963
2024-01-30 09:48:38,290:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:48:38,291:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 09:48:38,291:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:48:38,339:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:48:38,340:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:48:38,356:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:48:38,357:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:48:38,391:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.034028 secs. 1 sparse feature groups
2024-01-30 09:48:38,405:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008237
2024-01-30 09:48:38,426:INFO:[LightGBM] [Info] Start training from score 0.008237
2024-01-30 09:48:38,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:39,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:41,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:42,673:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:42,673:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:42,673:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:42,729:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:42,729:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:42,729:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:43,005:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:43,005:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:43,005:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:43,519:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:43,519:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:43,519:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:44,662:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:44,662:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:44,662:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:44,711:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:44,712:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:44,712:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:44,712:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74963
2024-01-30 09:48:44,712:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:48:44,713:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:48:44,713:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:48:44,763:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:48:44,764:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:48:44,768:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:48:44,771:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:48:44,773:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.002175 secs. 1 sparse feature groups
2024-01-30 09:48:44,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008237
2024-01-30 09:48:44,774:INFO:[LightGBM] [Info] Start training from score 0.008237
2024-01-30 09:48:45,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:45,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:46,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:47,651:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:47,652:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:47,652:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:47,723:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:47,723:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:47,723:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:48,019:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:48,019:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:48,019:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:48,504:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:48,504:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:48,504:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:49,650:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:49,650:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:49,650:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:49,698:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:49,698:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:49,698:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:49,698:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74963
2024-01-30 09:48:49,699:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:48:49,700:INFO:[LightGBM] [Info] Total Bins 114
2024-01-30 09:48:49,700:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:48:49,755:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:48:49,755:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:48:49,759:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:48:49,761:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:48:49,763:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001600 secs. 1 sparse feature groups
2024-01-30 09:48:49,763:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008237
2024-01-30 09:48:49,763:INFO:[LightGBM] [Info] Start training from score 0.008237
2024-01-30 09:48:50,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:50,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:51,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:52,838:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:52,838:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:52,838:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:52,907:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:52,907:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:52,907:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:53,216:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:53,216:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:53,216:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:53,816:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:53,816:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:53,816:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:54,953:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:54,953:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:54,953:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:55,001:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:55,001:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:55,001:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:55,001:INFO:[LightGBM] [Info] Number of positive: 75582, number of negative: 74964
2024-01-30 09:48:55,002:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:48:55,002:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:48:55,002:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:48:55,058:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:48:55,058:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:48:55,062:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:48:55,064:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:48:55,066:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.002487 secs. 1 sparse feature groups
2024-01-30 09:48:55,067:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502053 -> initscore=0.008210
2024-01-30 09:48:55,067:INFO:[LightGBM] [Info] Start training from score 0.008210
2024-01-30 09:48:55,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:55,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:55,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:55,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:55,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:55,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:55,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:55,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:56,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:57,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:48:58,219:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:58,219:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:58,219:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:58,273:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:58,274:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:58,274:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:58,548:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:58,548:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:58,548:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:48:59,045:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:48:59,046:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:48:59,046:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:00,235:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:00,235:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:00,235:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:00,281:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:00,282:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:00,282:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:00,282:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:00,283:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:00,283:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 09:49:00,284:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:00,334:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:00,335:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:00,348:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:00,357:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:00,366:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.009008 secs. 1 sparse feature groups
2024-01-30 09:49:00,367:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:00,367:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:00,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:00,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:00,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:00,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:00,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:00,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:01,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:02,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:03,630:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:03,630:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:03,630:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:03,710:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:03,710:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:03,710:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:04,047:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:04,047:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:04,047:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:04,667:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:04,667:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:04,667:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:05,789:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:05,789:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:05,789:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:05,844:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:05,844:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:05,844:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:05,844:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:05,844:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:05,845:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 09:49:05,845:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:05,897:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:05,898:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:05,902:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:05,903:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:05,905:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001636 secs. 1 sparse feature groups
2024-01-30 09:49:05,906:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:05,907:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:06,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:06,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:07,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:08,897:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:08,897:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:08,897:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:08,951:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:08,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:08,951:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:09,238:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:09,239:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:09,239:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:09,748:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:09,749:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:09,749:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:10,904:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:10,904:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:10,904:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:10,951:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:10,951:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:10,951:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:10,951:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:10,951:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:10,952:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:10,952:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:11,008:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:11,008:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:11,013:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:11,015:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:11,016:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001709 secs. 1 sparse feature groups
2024-01-30 09:49:11,017:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:11,017:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:11,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:11,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:11,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:11,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:11,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:11,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:11,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:12,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:13,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:14,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:14,116:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:14,116:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:14,116:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:14,183:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:14,183:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:14,184:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:14,470:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:14,471:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:14,471:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:15,026:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:15,026:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:15,026:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:16,187:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:16,187:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:16,188:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:16,253:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:16,253:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:16,253:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:16,254:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:16,254:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:16,256:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:16,256:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:16,310:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:16,310:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:16,314:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:16,316:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:16,318:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.002045 secs. 1 sparse feature groups
2024-01-30 09:49:16,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:16,318:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:16,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:16,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:16,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:16,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:16,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:16,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:17,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:18,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:19,390:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:19,390:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:19,390:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:19,443:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:19,443:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:19,443:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:19,718:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:19,718:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:19,718:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:20,273:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:20,273:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:20,273:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:21,435:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:21,436:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:21,436:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:21,483:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:21,483:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:21,484:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:21,484:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:21,484:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:21,485:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:21,485:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:21,536:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:21,536:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:21,541:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:21,542:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:21,544:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001590 secs. 1 sparse feature groups
2024-01-30 09:49:21,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:21,544:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:21,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:21,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:21,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:21,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:21,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:21,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:22,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:23,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2024-01-30 09:49:24,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:24,492:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:24,492:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:24,492:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:24,579:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:24,579:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:24,579:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:24,872:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:24,872:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:24,872:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:25,468:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:25,468:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:25,468:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:26,644:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:26,644:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:26,644:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:26,693:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:26,693:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:26,693:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:26,693:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:26,693:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:26,694:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:26,694:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:26,748:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:26,748:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:26,756:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:26,757:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:26,759:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001668 secs. 1 sparse feature groups
2024-01-30 09:49:26,759:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:26,760:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:26,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:27,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:28,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:29,708:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:29,708:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:29,708:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:29,780:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:29,780:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:29,780:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:30,068:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:30,069:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:30,069:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:30,584:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:30,584:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:30,584:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:31,257:INFO:Calculating mean and std
2024-01-30 09:49:31,258:INFO:Creating metrics dataframe
2024-01-30 09:49:31,263:INFO:Finalizing model
2024-01-30 09:49:31,737:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:31,737:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:31,737:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:31,788:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:31,788:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:31,788:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:31,788:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 09:49:31,788:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:31,790:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 09:49:31,790:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 38
2024-01-30 09:49:31,838:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:31,838:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:31,842:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:31,843:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:31,845:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.001459 secs. 1 sparse feature groups
2024-01-30 09:49:31,845:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 09:49:31,846:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 09:49:32,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:32,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:32,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:32,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:33,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:33,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:33,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:33,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:33,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:33,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:34,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:35,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-30 09:49:36,082:INFO:Initializing predict_model()
2024-01-30 09:49:36,082:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['total_leads_droppped',
                                             'city_tier', 'referred_lead'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transformer...
                                importance_type='split',
                                learning_rate=0.02763687273676973, max_depth=-1,
                                min_child_samples=9, min_child_weight=0.001,
                                min_split_gain=0.13835866595104254,
                                n_estimators=217, n_jobs=-1, num_leaves=135,
                                objective=None, random_state=42,
                                reg_alpha=1.4291476325379542e-10,
                                reg_lambda=1.3732436522309388e-05,
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f64e48b3be0>)
2024-01-30 09:49:36,082:INFO:Checking exceptions
2024-01-30 09:49:36,082:INFO:Preloading libraries
2024-01-30 09:49:36,082:INFO:Set up data.
2024-01-30 09:49:36,089:INFO:Set up index.
2024-01-30 09:49:37,848:INFO:Uploading results into container
2024-01-30 09:49:37,849:INFO:Uploading model into container now
2024-01-30 09:49:37,849:INFO:_master_model_container: 10
2024-01-30 09:49:37,849:INFO:_display_container: 4
2024-01-30 09:49:37,850:INFO:LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-30 09:49:37,850:INFO:create_model() successfully completed......................................
2024-01-30 09:49:37,936:INFO:SubProcess create_model() end ==================================
2024-01-30 09:49:37,937:INFO:choose_better activated
2024-01-30 09:49:37,939:INFO:SubProcess create_model() called ==================================
2024-01-30 09:49:37,939:INFO:Initializing create_model()
2024-01-30 09:49:37,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-01-30 09:49:37,940:INFO:Checking exceptions
2024-01-30 09:49:37,941:INFO:Importing libraries
2024-01-30 09:49:37,941:INFO:Copying training dataset
2024-01-30 09:49:37,964:INFO:Defining folds
2024-01-30 09:49:37,964:INFO:Declaring metric variables
2024-01-30 09:49:37,965:INFO:Importing untrained model
2024-01-30 09:49:37,965:INFO:Declaring custom model
2024-01-30 09:49:37,965:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-30 09:49:37,965:INFO:Starting cross validation
2024-01-30 09:49:37,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2024-01-30 09:49:38,588:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74963
2024-01-30 09:49:38,590:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:38,601:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 09:49:38,601:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:49:38,657:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:38,657:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:38,666:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:38,667:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:38,669:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001605 secs. 1 sparse feature groups
2024-01-30 09:49:38,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008237
2024-01-30 09:49:38,669:INFO:[LightGBM] [Info] Start training from score 0.008237
2024-01-30 09:49:40,961:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74963
2024-01-30 09:49:40,962:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:40,962:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:40,962:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:49:41,021:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:41,021:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:41,028:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:41,029:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:41,032:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.002873 secs. 1 sparse feature groups
2024-01-30 09:49:41,033:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008237
2024-01-30 09:49:41,034:INFO:[LightGBM] [Info] Start training from score 0.008237
2024-01-30 09:49:42,268:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74963
2024-01-30 09:49:42,268:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:42,269:INFO:[LightGBM] [Info] Total Bins 114
2024-01-30 09:49:42,269:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:49:42,319:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:42,319:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:42,324:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:42,325:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:42,327:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups
2024-01-30 09:49:42,328:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502059 -> initscore=0.008237
2024-01-30 09:49:42,328:INFO:[LightGBM] [Info] Start training from score 0.008237
2024-01-30 09:49:43,910:INFO:[LightGBM] [Info] Number of positive: 75582, number of negative: 74964
2024-01-30 09:49:43,911:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:43,912:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:43,912:INFO:[LightGBM] [Info] Number of data points in the train set: 150546, number of used features: 38
2024-01-30 09:49:43,961:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:43,961:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:43,966:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:43,967:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:43,969:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001883 secs. 1 sparse feature groups
2024-01-30 09:49:43,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502053 -> initscore=0.008210
2024-01-30 09:49:43,970:INFO:[LightGBM] [Info] Start training from score 0.008210
2024-01-30 09:49:45,184:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:45,184:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:45,185:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 09:49:45,185:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:45,235:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:45,235:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:45,240:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:45,242:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:45,243:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001635 secs. 1 sparse feature groups
2024-01-30 09:49:45,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:45,244:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:46,390:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:46,390:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:46,391:INFO:[LightGBM] [Info] Total Bins 115
2024-01-30 09:49:46,392:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:46,442:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:46,442:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:46,447:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:46,448:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:46,451:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001853 secs. 1 sparse feature groups
2024-01-30 09:49:46,451:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:46,452:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:47,559:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:47,560:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:47,561:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:47,561:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:47,612:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:47,612:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:47,617:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:47,618:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:47,620:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001600 secs. 1 sparse feature groups
2024-01-30 09:49:47,621:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:47,621:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:48,749:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:48,749:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:48,750:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:48,750:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:48,807:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:48,807:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:48,812:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:48,813:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:48,815:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001675 secs. 1 sparse feature groups
2024-01-30 09:49:48,815:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:48,815:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:49,949:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:49,949:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:49,950:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:49,950:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:50,000:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:50,000:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:50,004:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:50,005:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:50,007:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.001566 secs. 1 sparse feature groups
2024-01-30 09:49:50,007:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:50,007:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:51,230:INFO:[LightGBM] [Info] Number of positive: 75583, number of negative: 74964
2024-01-30 09:49:51,230:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:51,233:INFO:[LightGBM] [Info] Total Bins 116
2024-01-30 09:49:51,234:INFO:[LightGBM] [Info] Number of data points in the train set: 150547, number of used features: 38
2024-01-30 09:49:51,288:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:51,289:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:51,293:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:51,294:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:51,297:INFO:[LightGBM] [Info] 5 dense feature groups (1.15 MB) transferred to GPU in 0.002251 secs. 1 sparse feature groups
2024-01-30 09:49:51,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502056 -> initscore=0.008223
2024-01-30 09:49:51,297:INFO:[LightGBM] [Info] Start training from score 0.008223
2024-01-30 09:49:51,877:INFO:Calculating mean and std
2024-01-30 09:49:51,877:INFO:Creating metrics dataframe
2024-01-30 09:49:51,879:INFO:Finalizing model
2024-01-30 09:49:52,406:INFO:[LightGBM] [Info] Number of positive: 83981, number of negative: 83293
2024-01-30 09:49:52,406:INFO:[LightGBM] [Info] This is the GPU trainer!!
2024-01-30 09:49:52,407:INFO:[LightGBM] [Info] Total Bins 117
2024-01-30 09:49:52,408:INFO:[LightGBM] [Info] Number of data points in the train set: 167274, number of used features: 38
2024-01-30 09:49:52,459:INFO:[LightGBM] [Info] Using GPU Device: NVIDIA GeForce GTX 1070 Ti, Vendor: NVIDIA Corporation
2024-01-30 09:49:52,459:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...
2024-01-30 09:49:52,464:INFO:[LightGBM] [Info] GPU programs have been built
2024-01-30 09:49:52,467:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2024-01-30 09:49:52,469:INFO:[LightGBM] [Info] 5 dense feature groups (1.28 MB) transferred to GPU in 0.001978 secs. 1 sparse feature groups
2024-01-30 09:49:52,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502057 -> initscore=0.008226
2024-01-30 09:49:52,469:INFO:[LightGBM] [Info] Start training from score 0.008226
2024-01-30 09:49:52,976:INFO:Uploading results into container
2024-01-30 09:49:52,977:INFO:Uploading model into container now
2024-01-30 09:49:52,977:INFO:_master_model_container: 11
2024-01-30 09:49:52,977:INFO:_display_container: 5
2024-01-30 09:49:52,978:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-30 09:49:52,978:INFO:create_model() successfully completed......................................
2024-01-30 09:49:53,058:INFO:SubProcess create_model() end ==================================
2024-01-30 09:49:53,059:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=42, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8205
2024-01-30 09:49:53,059:INFO:LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for AUC is 0.8208
2024-01-30 09:49:53,060:INFO:LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-30 09:49:53,060:INFO:choose_better completed
2024-01-30 09:49:53,060:INFO:Creating Dashboard logs
2024-01-30 09:49:53,062:INFO:Model: Light Gradient Boosting Machine
2024-01-30 09:49:53,100:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.02763687273676973, 'max_depth': -1, 'min_child_samples': 9, 'min_child_weight': 0.001, 'min_split_gain': 0.13835866595104254, 'n_estimators': 217, 'n_jobs': -1, 'num_leaves': 135, 'objective': None, 'random_state': 42, 'reg_alpha': 1.4291476325379542e-10, 'reg_lambda': 1.3732436522309388e-05, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'device': 'gpu', 'feature_fraction': 0.7953631875848566, 'bagging_fraction': 0.8026208127603797, 'bagging_freq': 1}
2024-01-30 09:49:53,372:INFO:Initializing predict_model()
2024-01-30 09:49:53,372:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, estimator=LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f64e484e7a0>)
2024-01-30 09:49:53,372:INFO:Checking exceptions
2024-01-30 09:49:53,373:INFO:Preloading libraries
2024-01-30 09:49:54,209:INFO:SubProcess plot_model() called ==================================
2024-01-30 09:49:54,210:INFO:Initializing plot_model()
2024-01-30 09:49:54,210:INFO:plot_model(plot=auc, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpfma2hwt8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 09:49:54,210:INFO:Checking exceptions
2024-01-30 09:49:54,222:INFO:Preloading libraries
2024-01-30 09:49:54,252:INFO:Copying training dataset
2024-01-30 09:49:54,253:INFO:Plot type: auc
2024-01-30 09:49:54,420:INFO:Fitting Model
2024-01-30 09:49:54,423:INFO:Scoring test/hold-out set
2024-01-30 09:49:54,430:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:54,430:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:54,430:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:54,682:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:54,683:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:54,683:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:54,964:INFO:Saving '/tmp/tmpfma2hwt8/AUC.png'
2024-01-30 09:49:55,165:INFO:Visual Rendered Successfully
2024-01-30 09:49:55,280:INFO:plot_model() successfully completed......................................
2024-01-30 09:49:55,281:INFO:Initializing plot_model()
2024-01-30 09:49:55,281:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpfma2hwt8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 09:49:55,281:INFO:Checking exceptions
2024-01-30 09:49:55,294:INFO:Preloading libraries
2024-01-30 09:49:55,368:INFO:Copying training dataset
2024-01-30 09:49:55,368:INFO:Plot type: confusion_matrix
2024-01-30 09:49:55,562:INFO:Fitting Model
2024-01-30 09:49:55,565:INFO:Scoring test/hold-out set
2024-01-30 09:49:55,576:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:55,576:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:55,576:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:55,903:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2024-01-30 09:49:55,903:INFO:[LightGBM] [Warning] feature_fraction is set=0.7953631875848566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7953631875848566
2024-01-30 09:49:55,903:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8026208127603797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8026208127603797
2024-01-30 09:49:56,176:INFO:Saving '/tmp/tmpfma2hwt8/Confusion Matrix.png'
2024-01-30 09:49:56,288:INFO:Visual Rendered Successfully
2024-01-30 09:49:56,386:INFO:plot_model() successfully completed......................................
2024-01-30 09:49:56,387:INFO:Initializing plot_model()
2024-01-30 09:49:56,387:INFO:plot_model(plot=feature, fold=None, verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=/tmp/tmpfma2hwt8, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f64e41fd5a0>, system=False)
2024-01-30 09:49:56,388:INFO:Checking exceptions
2024-01-30 09:49:56,402:INFO:Preloading libraries
2024-01-30 09:49:56,455:INFO:Copying training dataset
2024-01-30 09:49:56,455:INFO:Plot type: feature
2024-01-30 09:49:56,464:WARNING:No coef_ found. Trying feature_importances_
2024-01-30 09:49:56,538:INFO:Saving '/tmp/tmpfma2hwt8/Feature Importance.png'
2024-01-30 09:49:56,674:INFO:Visual Rendered Successfully
2024-01-30 09:49:56,760:INFO:plot_model() successfully completed......................................
2024-01-30 09:49:56,761:INFO:SubProcess plot_model() end ==================================
2024-01-30 09:49:56,967:INFO:_master_model_container: 11
2024-01-30 09:49:56,967:INFO:_display_container: 4
2024-01-30 09:49:56,968:INFO:LGBMClassifier(bagging_fraction=0.8026208127603797, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', feature_fraction=0.7953631875848566,
               importance_type='split', learning_rate=0.02763687273676973,
               max_depth=-1, min_child_samples=9, min_child_weight=0.001,
               min_split_gain=0.13835866595104254, n_estimators=217, n_jobs=-1,
               num_leaves=135, objective=None, random_state=42,
               reg_alpha=1.4291476325379542e-10,
               reg_lambda=1.3732436522309388e-05, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-30 09:49:56,968:INFO:tune_model() successfully completed......................................
